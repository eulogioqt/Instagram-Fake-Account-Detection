[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Detección de cuentas falsas de Instagram",
    "section": "",
    "text": "1 Introducción\nEste libro ha sido escrito por Eulogio Quemada Torres, alumno de Laboratorio de Computación Cíentífica como asignatura optativa en el grado de Ingeniería del Software, impartida por el profesor Ángel Mora Bonilla.\nEl propósito del mismo es analizar los datos propuestos en el dataset de Kaggle. Este dataset contiene información sobre distintas cuentas de Instagram y si son falsas o reales.\nAntes de comenzar vamos a describir las distintas variables que tenemos en nuestro dataset. Será de vital importancia entender el significado cada una para poder seguir el hilo de las técnicas de análisis de datos que se aplicarán durante este libro."
  },
  {
    "objectID": "index.html#variables",
    "href": "index.html#variables",
    "title": "Detección de cuentas falsas de Instagram",
    "section": "1.1 Variables",
    "text": "1.1 Variables\n\n1.1.1 profile pic\nIndica si la cuenta tiene foto de perfil o no. Los usuarios nuevos por defecto no tienen ninguna foto de perfil, lo que las cuentas falsas puede que luego no usen.\n\n\n1.1.2 nums/length username\nEs la proporción de números sobre la longitud total de carácteres en el nombre de usuario. Ciertas cuentas reales tienen algún número en la cuenta, algunos su día de nacimiento, su año, algún número que les guste. Pero tener muchos números puede ser algo raro.\n\n\n1.1.3 fullname words\nNúmero de palabras en el nombre completo. Un nombre de una persona europea suele tener 2 o 3 palabras, en función de los apellidos, algunos más, algunos menos, pero cercano a esto.\n\n\n1.1.4 nums/length fullname\nEs la proporción de números sobre la longitud del nombre completo. Un nombre de persona, en la mayoría de países del mundo, no puede tener números, así que la presencia de estos puede ser indicativo de que algo está pasando.\n\n\n1.1.5 name==username\nIndica si el nombre de usuario y el nombre real de la cuenta es el mismo. No es lo normal que sea exactamente el mismo, puede ser indicativo de algo extraño.\n\n\n1.1.6 description length\nRepresenta el número de carácteres en la descripción de la cuenta de Instagram.\n\n\n1.1.7 external URL\nIndica si la cuenta tiene un enlace externo o no, en su perfil.\n\n\n1.1.8 private\nIndica si la cuenta es privada o no.\n\n\n1.1.9 posts\nNúmero de publicaciones realizadas por la cuenta de Instagram.\n\n\n1.1.10 followers\nNúmero de seguidores de la cuenta de Instagram.\n\n\n1.1.11 follows\nNúmero de personas a las que sigue la cuenta de Instagram.\n\n\n1.1.12 fake\nEs la clasificación. Un 1 para las cuentas clasificadas como falsas, un 0 para las reales."
  },
  {
    "objectID": "index.html#próximos-pasos",
    "href": "index.html#próximos-pasos",
    "title": "Detección de cuentas falsas de Instagram",
    "section": "1.2 Próximos pasos",
    "text": "1.2 Próximos pasos\nDurante este libro intentaremos aplicar las técnicas aprendidas en la asignatura para el análisis de datos. Algunas técnicas pueden que no sean aplicables, otras pueden ser mejores o peores, pero intentaremos extraer conocimiento de los datos y sacar conclusiones interesantes."
  },
  {
    "objectID": "exploratory_analysis.html#exploración-inicial-del-dataset",
    "href": "exploratory_analysis.html#exploración-inicial-del-dataset",
    "title": "2  Análisis exploratorio de datos",
    "section": "2.1 Exploración inicial del dataset",
    "text": "2.1 Exploración inicial del dataset\nVamos a comenzar viendo los aspectos más generales de nuestro dataset, que involucren toda la información, luego nos centraremos en aspectos más concretos.\n\n2.1.1 Estructura del dataset\n\nstr(dataset)\n\n'data.frame':   576 obs. of  12 variables:\n $ profile.pic         : int  1 1 1 1 1 1 1 1 1 1 ...\n $ nums.length.username: num  0.27 0 0.1 0 0 0 0 0 0 0 ...\n $ fullname.words      : int  0 2 2 1 2 4 2 2 0 2 ...\n $ nums.length.fullname: num  0 0 0 0 0 0 0 0 0 0 ...\n $ name..username      : int  0 0 0 0 0 0 0 0 0 0 ...\n $ description.length  : int  53 44 0 82 0 81 50 0 71 40 ...\n $ external.URL        : int  0 0 0 0 0 1 0 0 0 1 ...\n $ private             : int  0 0 1 0 1 0 0 0 0 0 ...\n $ X.posts             : int  32 286 13 679 6 344 16 33 72 213 ...\n $ X.followers         : int  1000 2740 159 414 151 669987 122 1078 1824 12945 ...\n $ X.follows           : int  955 533 98 651 126 150 177 76 2713 813 ...\n $ fake                : int  0 0 0 0 0 0 0 0 0 0 ...\n\n\nVemos que contamos con 576 observaciones, es decir, 576 cuentas de Instagram con su clasificación y 12 variables que son precisamente los datos que tenemos de estas cuentas.\nInicialmente podemos ver que todas nuestras variables son númericas, ya sean números enteros o decimales. Para el análisis de datos esto es un plus, pues los números son más manejables para la mayoría de técnicas de análisis de datos.\n\n\n2.1.2 Valores NA\n\nsapply(dataset, function(x) sum(is.na(x)))\n\n         profile.pic nums.length.username       fullname.words \n                   0                    0                    0 \nnums.length.fullname       name..username   description.length \n                   0                    0                    0 \n        external.URL              private              X.posts \n                   0                    0                    0 \n         X.followers            X.follows                 fake \n                   0                    0                    0 \n\n\nSorprendentemente no hay valores nulos, en los datasets suele haber columnas con valores NA con los que debemos tener cuidado, pero en nuestro caso, no tenemos ninguno, lo que de nuevo, nos facilitará el trabajo a lo largo de este libro.\n\n\n2.1.3 Resumen estadístico\n\nsummary(dataset)\n\n  profile.pic     nums.length.username fullname.words  nums.length.fullname\n Min.   :0.0000   Min.   :0.0000       Min.   : 0.00   Min.   :0.00000     \n 1st Qu.:0.0000   1st Qu.:0.0000       1st Qu.: 1.00   1st Qu.:0.00000     \n Median :1.0000   Median :0.0000       Median : 1.00   Median :0.00000     \n Mean   :0.7014   Mean   :0.1638       Mean   : 1.46   Mean   :0.03609     \n 3rd Qu.:1.0000   3rd Qu.:0.3100       3rd Qu.: 2.00   3rd Qu.:0.00000     \n Max.   :1.0000   Max.   :0.9200       Max.   :12.00   Max.   :1.00000     \n name..username    description.length  external.URL       private      \n Min.   :0.00000   Min.   :  0.00     Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.00000   1st Qu.:  0.00     1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.00000   Median :  0.00     Median :0.0000   Median :0.0000  \n Mean   :0.03472   Mean   : 22.62     Mean   :0.1163   Mean   :0.3819  \n 3rd Qu.:0.00000   3rd Qu.: 34.00     3rd Qu.:0.0000   3rd Qu.:1.0000  \n Max.   :1.00000   Max.   :150.00     Max.   :1.0000   Max.   :1.0000  \n    X.posts        X.followers         X.follows           fake    \n Min.   :   0.0   Min.   :       0   Min.   :   0.0   Min.   :0.0  \n 1st Qu.:   0.0   1st Qu.:      39   1st Qu.:  57.5   1st Qu.:0.0  \n Median :   9.0   Median :     150   Median : 229.5   Median :0.5  \n Mean   : 107.5   Mean   :   85307   Mean   : 508.4   Mean   :0.5  \n 3rd Qu.:  81.5   3rd Qu.:     716   3rd Qu.: 589.5   3rd Qu.:1.0  \n Max.   :7389.0   Max.   :15338538   Max.   :7500.0   Max.   :1.0  \n\n\nObservamos que hay algunas variables binarias, otras con pocos valores y otras con un rango amplio. Vamos a usar las funciones apply para entrar un poco más en profundidad.\n\nminimums &lt;- sapply(dataset, min)\nmaximums &lt;- sapply(dataset, max)\nunique_values &lt;- sapply(dataset, function(x) length(unique(x)))\n\ndataset_values &lt;- data.frame(\n  min=minimums,\n  max=maximums,\n  unique_values=unique_values\n)\n\ndataset_values\n\n                     min         max unique_values\nprofile.pic            0        1.00             2\nnums.length.username   0        0.92            54\nfullname.words         0       12.00             9\nnums.length.fullname   0        1.00            25\nname..username         0        1.00             2\ndescription.length     0      150.00           104\nexternal.URL           0        1.00             2\nprivate                0        1.00             2\nX.posts                0     7389.00           193\nX.followers            0 15338538.00           372\nX.follows              0     7500.00           400\nfake                   0        1.00             2\n\n\nIdentificamos fácilmente que hay 5 variables binarias, 3 no binarias con menos de 100 valores distintos y el resto con 100 o más valores distintos. Estas variables son:\n\nbinary_vars &lt;- rownames(dataset_values %&gt;% filter(unique_values == 2))\n\n\n\nVariables binarias son: profile.pic, name..username, external.URL, private, fake \n\n\n\nmid_vars &lt;- rownames(dataset_values %&gt;% filter(unique_values &gt; 2 & unique_values &lt; 100))\n\n\n\nVariables con entre 2 y 100: nums.length.username, fullname.words, nums.length.fullname \n\n\n\nbig_vars &lt;- rownames(dataset_values %&gt;% filter(unique_values &gt;= 100))\n\n\n\nVariables con 100 o más: description.length, X.posts, X.followers, X.follows"
  },
  {
    "objectID": "exploratory_analysis.html#gráfico-de-pares",
    "href": "exploratory_analysis.html#gráfico-de-pares",
    "title": "2  Análisis exploratorio de datos",
    "section": "2.2 Gráfico de pares",
    "text": "2.2 Gráfico de pares\nVamos a visualizar el panel de pares de variables, que nos da información de la relación entre cada par de variables.\n\npairs.panels(dataset, main=\"Gráfico de pares\")\n\n\n\n\nEs un poco díficil observar algo ya que tenemos 12 variables y los gráficos se ven muy pequeños. Vamos a observar la matriz de correlación."
  },
  {
    "objectID": "exploratory_analysis.html#matriz-de-correlación",
    "href": "exploratory_analysis.html#matriz-de-correlación",
    "title": "2  Análisis exploratorio de datos",
    "section": "2.3 Matriz de correlación",
    "text": "2.3 Matriz de correlación\nLa matriz de correlación nos muestra la correlación entre cada par de variables. Sea M la matriz de correlación y sea (i, j) una posición de la matriz, entonces, la posición M[i, j] es la correlación entre las variables i y j.\n\ncor_matrix &lt;- cor(dataset)\ncor_matrix\n\n                     profile.pic nums.length.username fullname.words\nprofile.pic           1.00000000          -0.36408701     0.21329514\nnums.length.username -0.36408701           1.00000000    -0.22547213\nfullname.words        0.21329514          -0.22547213     1.00000000\nnums.length.fullname -0.13175622           0.40856654    -0.09434799\nname..username       -0.12490287           0.05688965    -0.08296878\ndescription.length    0.36789194          -0.32117027     0.27252216\nexternal.URL          0.23672932          -0.23712479     0.19656239\nprivate               0.11473196          -0.06371257    -0.08907008\nX.posts               0.16957023          -0.15744211     0.07335018\nX.followers           0.06113663          -0.06278509     0.03322460\nX.follows             0.19483278          -0.17241327     0.09485496\nfake                 -0.63731535           0.58768653    -0.29879258\n                     nums.length.fullname name..username description.length\nprofile.pic                   -0.13175622   -0.124902870        0.367891938\nnums.length.username           0.40856654    0.056889649       -0.321170271\nfullname.words                -0.09434799   -0.082968780        0.272522165\nnums.length.fullname           1.00000000    0.291149086       -0.117521050\nname..username                 0.29114909    1.000000000       -0.064813853\ndescription.length            -0.11752105   -0.064813853        1.000000000\nexternal.URL                  -0.08872418   -0.039232382        0.482313071\nprivate                       -0.03003033    0.046084001       -0.110328832\nX.posts                       -0.05771550   -0.049808246        0.144823702\nX.followers                   -0.02703471   -0.017760756        0.005929455\nX.follows                     -0.06797109   -0.009529101        0.226561422\nfake                           0.24678210    0.170694729       -0.460824593\n                     external.URL     private     X.posts  X.followers\nprofile.pic            0.23672932  0.11473196  0.16957023  0.061136635\nnums.length.username  -0.23712479 -0.06371257 -0.15744211 -0.062785090\nfullname.words         0.19656239 -0.08907008  0.07335018  0.033224604\nnums.length.fullname  -0.08872418 -0.03003033 -0.05771550 -0.027034712\nname..username        -0.03923238  0.04608400 -0.04980825 -0.017760756\ndescription.length     0.48231307 -0.11032883  0.14482370  0.005929455\nexternal.URL           1.00000000 -0.16261231  0.16500846  0.027188730\nprivate               -0.16261231  1.00000000 -0.08749503 -0.073472710\nX.posts                0.16500846 -0.08749503  1.00000000  0.321385480\nX.followers            0.02718873 -0.07347271  0.32138548  1.000000000\nX.follows              0.14251936 -0.05754247  0.09822504 -0.011065994\nfake                  -0.36280938 -0.02858602 -0.24535515 -0.093688783\n                        X.follows        fake\nprofile.pic           0.194832776 -0.63731535\nnums.length.username -0.172413275  0.58768653\nfullname.words        0.094854964 -0.29879258\nnums.length.fullname -0.067971092  0.24678210\nname..username       -0.009529101  0.17069473\ndescription.length    0.226561422 -0.46082459\nexternal.URL          0.142519361 -0.36280938\nprivate              -0.057542468 -0.02858602\nX.posts               0.098225040 -0.24535515\nX.followers          -0.011065994 -0.09368878\nX.follows             1.000000000 -0.22483522\nfake                 -0.224835224  1.00000000\n\n\nAquí podemos buscar cualquier par de variables y ver su correlación. Buscando un poco vemos correlaciones significativas entre profile.pic y fake, la description.length y external.URL\nComo hay muchos numeros y no es lo más riguroso buscar a ojo, vamos a hacer unos pequeños cálculos para encontrar todas las variables relacionadas más de un cierto threshold.\n\nthreshold &lt;- 0.4\n\ncor_table &lt;- data.frame(as.table(cor_matrix)) %&gt;% \n  rename(Correlation = Freq)\n\nvariables &lt;- colnames(dataset)\nn_variables &lt;- length(dataset)\nmedium_point &lt;- n_variables / 2\n\n# Para que no haya repeticiones simétricas, vamos a poner la restricción de que el \n# orden léxicográfico de una variable sea mayor (o menor) que la otra. \n# Con un != no valdría porque habría valores filas simétricas\ncor_table %&gt;% \n  filter(as.character(Var1) &gt; as.character(Var2) & abs(Correlation) &gt; threshold) %&gt;%\n  arrange(desc(abs(Correlation)))\n\n                  Var1                 Var2 Correlation\n1          profile.pic                 fake  -0.6373153\n2 nums.length.username                 fake   0.5876865\n3         external.URL   description.length   0.4823131\n4                 fake   description.length  -0.4608246\n5 nums.length.username nums.length.fullname   0.4085665\n\n\nAhora podemos sacar más información que la que habíamos visto de primeras. Hay una importante correlación entre si una cuenta es falsa y si tiene foto de perfil, el ratio de carácteres númericos en el nombre de la cuenta, la longitud de la descripción…\nA conitnuación vamos a pasar a un análsis más concreto, para observar en particular cada variable de nuestro dataset."
  },
  {
    "objectID": "exploratory_analysis.html#variables-binarias",
    "href": "exploratory_analysis.html#variables-binarias",
    "title": "2  Análisis exploratorio de datos",
    "section": "2.4 Variables binarias",
    "text": "2.4 Variables binarias\nLas variables binarias solo toman dos valores (en nuestro caso todas 0 o 1) y la información que se puede extraer es distinta que el resto. Vamos a comenzar con ellas, como sabemos por nuestro análisis anterior, estás son profile.pic, name..username, external.URL y private y fake. Vamos a comenzar con fake ya que es la más relevante, pues es la clasificación de cada fila del dataset.\n\n2.4.1 fake\nToma el valor 1 si la cuenta es falsa, y 0 si no es falsa. Es la variable más importante que tenemos en el dataset, pues es la que tratamos de estimar, de la que queremos a partir de las otras, extraer información para poder predecir esta.\n\ntable(dataset$fake)\n\n\n  0   1 \n288 288 \n\n\nTenemos un 50 - 50 de clasificaciones, mitad de cuentas son falsas y la otra mitad no.\n\nsummary(dataset$fake)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0     0.0     0.5     0.5     1.0     1.0 \n\n\nLa media y la mediana corroboran lo que comentabamos antes.\nEn resumen:\n\ntotal_count &lt;- length(dataset$fake)\ncount_fake &lt;- sum(dataset$fake == 1)\ncount_real &lt;- sum(dataset$fake == 0)\npercent_fake &lt;- (count_fake / total_count) * 100\npercent_real &lt;- (count_real / total_count) * 100\n\npaste0(\"Cuentas falsas: \", count_fake, \" (\", round(percent_fake, 2), \"%)\")\n\n[1] \"Cuentas falsas: 288 (50%)\"\n\npaste0(\"Cuentas no falsas: \", count_real, \" (\", round(percent_real, 2), \"%)\")\n\n[1] \"Cuentas no falsas: 288 (50%)\"\n\n\n\n\n2.4.2 profile.pic\nToma el valor 1 para las cuentas con foto de perfil y un 0 para las que no tienen.\n\nsummary(dataset$profile.pic)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.7014  1.0000  1.0000 \n\n\nLa media ya nos indica que en nuestro dataset hay más cuentas con foto de perfil que sin foto.\nEn resumen:\n\n\n[1] \"Cuentas con foto de perfil: 404 (70.14%)\"\n\n\n[1] \"Cuentas sin foto de perfil: 172 (29.86%)\"\n\n\n\n\n2.4.3 name..username\nToma el valor 1 si el nombre de la persona es igual al username que se ha puesto en Instagram, y 0 en caso contrario.\n\nsummary(dataset$name..username)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00000 0.00000 0.03472 0.00000 1.00000 \n\n\nLa media nos indica que muy pocas cuentas cumplen esta condición.\n\ntotal_count &lt;- length(dataset$name..username)\ncount_name_equals_username &lt;- sum(dataset$name..username == 1)\ncount_name_not_equals_username &lt;- sum(dataset$name..username == 0)\npercent_name_equals_username &lt;- (count_name_equals_username / total_count) * 100\npercent_name_not_equals_username &lt;- (count_name_not_equals_username / total_count) * 100\n\npaste0(\"Cuentas con mismo nombre y username: \", count_name_equals_username, \" (\", round(percent_name_equals_username, 2), \"%)\")\n\n[1] \"Cuentas con mismo nombre y username: 20 (3.47%)\"\n\npaste0(\"Cuentas con distinto nombre y username: \", count_name_not_equals_username, \" (\", round(percent_name_not_equals_username, 2), \"%)\")\n\n[1] \"Cuentas con distinto nombre y username: 556 (96.53%)\"\n\n\n\n\n2.4.4 external.URL\nToma el valor 1 si la cuenta tiene un enlace en el perfil, y 0 si no tiene.\n\nsummary(dataset$external.URL)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.1163  0.0000  1.0000 \n\n\nLa mediana es 0 y la media 0.11. Pocas cuentas tienen enlace en el perfil.\n\ntotal_count &lt;- length(dataset$external.URL)\ncount_with_url &lt;- sum(dataset$external.URL == 1)\ncount_without_url &lt;- sum(dataset$external.URL == 0)\npercent_with_url &lt;- (count_with_url / total_count) * 100\npercent_without_url &lt;- (count_without_url / total_count) * 100\n\npaste0(\"Cuentas con enlace en el perfil: \", count_with_url, \" (\", round(percent_with_url, 2), \"%)\")\n\n[1] \"Cuentas con enlace en el perfil: 67 (11.63%)\"\n\npaste0(\"Cuentas sin enlace en el perfil: \", count_without_url, \" (\", round(percent_without_url, 2), \"%)\")\n\n[1] \"Cuentas sin enlace en el perfil: 509 (88.37%)\"\n\n\n\n\n2.4.5 private\nToma el valor 1 si la cuenta es privada, y 0 si es pública.\n\nsummary(dataset$private)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.3819  1.0000  1.0000 \n\n\n\ntotal_count &lt;- length(dataset$private)\ncount_private &lt;- sum(dataset$private == 1)\ncount_public &lt;- sum(dataset$private == 0)\npercent_private &lt;- (count_private / total_count) * 100\npercent_public &lt;- (count_public / total_count) * 100\n\npaste0(\"Cuentas privadas: \", count_private, \" (\", round(percent_private, 2), \"%)\")\n\n[1] \"Cuentas privadas: 220 (38.19%)\"\n\npaste0(\"Cuentas públicas: \", count_public, \" (\", round(percent_public, 2), \"%)\")\n\n[1] \"Cuentas públicas: 356 (61.81%)\""
  },
  {
    "objectID": "exploratory_analysis.html#variables-no-binarias",
    "href": "exploratory_analysis.html#variables-no-binarias",
    "title": "2  Análisis exploratorio de datos",
    "section": "2.5 Variables no binarias",
    "text": "2.5 Variables no binarias\nLas variables no binarias tienen más información que podemos explorar, las binarias simplemente podíamos ver como se repartían los datos y no mucho más.\nLas variables no binarias son:\n\nnon_binary &lt;- dataset_values %&gt;%\n  filter(unique_values &gt; 2) %&gt;%\n  arrange(unique_values)\n\nnon_binary\n\n                     min         max unique_values\nfullname.words         0       12.00             9\nnums.length.fullname   0        1.00            25\nnums.length.username   0        0.92            54\ndescription.length     0      150.00           104\nX.posts                0     7389.00           193\nX.followers            0 15338538.00           372\nX.follows              0     7500.00           400\n\n\nSalvo fullname.words, todas las variables tienen un alto número de valores únicos. Vamos a empezar con esta ya que podremos hacer algún que otro gráfico distinto al resto, y seguiremos el orden ascendente del número de valores únicos.\n\n2.5.1 fullname.words\nRepresenta el número de palabras en el nombre completo del usuario.\n\nstr(dataset$fullname.words)\n\n int [1:576] 0 2 2 1 2 4 2 2 0 2 ...\n\n\nVemos que toma valores enteros.\n\nsummary(dataset$fullname.words)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    1.00    1.00    1.46    2.00   12.00 \n\n\nLa media es alrededor de la palabra y media, lo que tiene bastante sentido. Sin embargo, la mediana es tener una sola palabra para el nombre.\n\ntable(dataset$fullname.words)\n\n\n  0   1   2   3   4   5   6  10  12 \n 57 283 187  34   7   4   2   1   1 \n\n\nTenemos bastantes cuentas sin palabras en el nombre completo, lo que es sospechoso.\n¿Qué tipo de cuenta tiene más de 1, 2, 3 o como mucho 4 palabras en su nombre completo? Es tan sospechoso como tener 0.\n\ntotal_count &lt;- nrow(dataset)\n\ncount_one_word &lt;- sum(dataset$fullname.words == 1)\npercent_one_word &lt;- (count_one_word / total_count) * 100\n\ncount_multi_word &lt;- sum(dataset$fullname.words &gt; 1)\npercent_multi_word &lt;- (count_multi_word / total_count) * 100\n\ncount_no_word &lt;- sum(dataset$fullname.words == 0)\npercent_no_word &lt;- (count_no_word / total_count) * 100\n\n# Mostrar resultados\npaste0(\"Cuentas sin nombre completo: \", count_no_word, \" (\", round(percent_no_word, 2), \"%)\")\n\n[1] \"Cuentas sin nombre completo: 57 (9.9%)\"\n\npaste0(\"Cuentas con nombre completo de una palabra: \", count_one_word, \" (\", round(percent_one_word, 2), \"%)\")\n\n[1] \"Cuentas con nombre completo de una palabra: 283 (49.13%)\"\n\npaste0(\"Cuentas con nombre de más de una palabra: \", count_multi_word, \" (\", round(percent_multi_word, 2), \"%)\")\n\n[1] \"Cuentas con nombre de más de una palabra: 236 (40.97%)\"\n\n\n\n\n2.5.2 nums.length.fullname\nRatio del número de carácteres númericos en el nombre completo respecto a la longitud del nombre completo.\n\nstr(dataset$nums.length.fullname)\n\n num [1:576] 0 0 0 0 0 0 0 0 0 0 ...\n\n\n\ntable(dataset$nums.length.fullname)\n\n\n   0 0.08  0.1 0.11 0.12 0.14 0.18  0.2 0.22 0.24 0.25 0.27 0.29 0.31 0.33 0.36 \n 518    1    1    1    2    1    2    1    3    3    4    1    1    3   11    2 \n0.38  0.4 0.43 0.44 0.46  0.5 0.57 0.89    1 \n   1    7    2    2    1    3    1    1    3 \n\n\nTenemos una gran concentración en el número 0 y vemos que la variable toma valores entre 0 y 1, de forma continua.\n\nsummary(dataset$nums.length.fullname)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00000 0.00000 0.03609 0.00000 1.00000 \n\n\nLo normal es no tener carácteres en el nombre completo (recordamos que es el nombre de la persona, no el username).\n\ntotal_count &lt;- nrow(dataset)\n\ncount_with_numbers &lt;- sum(dataset$nums.length.fullname &gt; 0)\npercent_with_numbers &lt;- (count_with_numbers / total_count) * 100\n\ncount_no_numbers &lt;- sum(dataset$nums.length.fullname == 0)\npercent_no_numbers &lt;- (count_no_numbers / total_count) * 100\n\npaste0(\"Cuentas con números en el nombre completo: \", \n       count_with_numbers, \" (\", round(percent_with_numbers, 2), \"%)\")\n\n[1] \"Cuentas con números en el nombre completo: 58 (10.07%)\"\n\npaste0(\"Cuentas sin números en el nombre completo: \", \n       count_no_numbers, \" (\", round(percent_no_numbers, 2), \"%)\")\n\n[1] \"Cuentas sin números en el nombre completo: 518 (89.93%)\"\n\n\n\n\n2.5.3 nums.length.username\nRatio del número de carácteres númericos en el nombre de usuario respecto a la longitud del nombre de usuario.\nMuy parecido a la variable anterior, pero esta vez es respecto al nombre de usuario de Instagram. Probablemente haya ciertas diferencias como que será más común tener algún número en el username.\n\nstr(dataset$nums.length.username)\n\n num [1:576] 0.27 0 0.1 0 0 0 0 0 0 0 ...\n\n\nToma valores entre 0 y 1, como la variable anterior.\n\nsummary(dataset$nums.length.username)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.1638  0.3100  0.9200 \n\n\nSe observa justamente lo que hemos comentado, es más común tener algún número en el username, respecto a los números en el nombre completo de la persona.\n\ntotal_count &lt;- nrow(dataset)\n\ncount_with_numbers &lt;- sum(dataset$nums.length.username &gt; 0)\npercent_with_numbers &lt;- (count_with_numbers / total_count) * 100\n\ncount_no_numbers &lt;- sum(dataset$nums.length.username == 0)\npercent_no_numbers &lt;- (count_no_numbers / total_count) * 100\n\npaste0(\"Cuentas con números en el nombre completo: \", \n       count_with_numbers, \" (\", round(percent_with_numbers, 2), \"%)\")\n\n[1] \"Cuentas con números en el nombre completo: 277 (48.09%)\"\n\npaste0(\"Cuentas sin números en el nombre completo: \", \n       count_no_numbers, \" (\", round(percent_no_numbers, 2), \"%)\")\n\n[1] \"Cuentas sin números en el nombre completo: 299 (51.91%)\"\n\n\nPrácticamente la mitad de usuarios tiene algún número en el nombre de usuario, mientras que en nombre completo, pocos tenían.\n\n\n2.5.4 description.length\nLa longitud de la descripción de la cuenta de Instagram.\n\nstr(dataset$description.length)\n\n int [1:576] 53 44 0 82 0 81 50 0 71 40 ...\n\n\nToma valores enteros, como es lógico por el significado de la variable.\n\nsummary(dataset$description.length)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    0.00   22.62   34.00  150.00 \n\n\nLa media es de unos 23 carácteres en la descripción, pero probablemente esté muy afectado por las cuentas sin descripción, ya que la mediana es 0.\n\ncount_with_description &lt;- sum(dataset$description.length &gt; 0)\npercent_with_description &lt;- (count_with_description / total_count) * 100\n\ncount_no_description &lt;- sum(dataset$description.length == 0)\npercent_no_description &lt;- (count_no_description / total_count) * 100\n\npaste0(\"Cuentas con descripción: \", \n       count_with_description, \" (\", round(percent_with_description, 2), \"%)\")\n\n[1] \"Cuentas con descripción: 250 (43.4%)\"\n\npaste0(\"Cuentas sin descripción: \", \n       count_no_description, \" (\", round(percent_no_description, 2), \"%)\")\n\n[1] \"Cuentas sin descripción: 326 (56.6%)\"\n\n\nHay más cuentas sin descripción que con descripción. Vamos a calcular la media sin tener en cuenta todas esas cuentas que no tienen descripción:\n\ncuentas_con_descripcion = dataset %&gt;%\n  filter(description.length &gt; 0)\n\npaste0(\"La media de carácteres en la descripción es: \", mean(cuentas_con_descripcion$description.length))\n\n[1] \"La media de carácteres en la descripción es: 52.124\"\n\n\n\n\n2.5.5 X.posts\nRepresenta el número de publicaciones que tiene una cuenta de Instagram.\n\nstr(dataset$X.posts)\n\n int [1:576] 32 286 13 679 6 344 16 33 72 213 ...\n\n\nDe nuevo, valores enteros.\n\nsummary(dataset$X.posts)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0     0.0     9.0   107.5    81.5  7389.0 \n\n\nEn este caso no pasa como con la descripción que la mediana era directamente 0, pero de nuevo vemos que la media es muy alta y la mediana muy baja.\n\ncount_with_posts &lt;- sum(dataset$X.posts &gt; 0)\ncount_no_posts &lt;- sum(dataset$X.posts == 0)\n\npercent_with_posts &lt;- (count_with_posts / total_count) * 100\npercent_no_posts &lt;- (count_no_posts / total_count) * 100\n\npaste0(\"Cuentas con publicaciones: \", count_with_posts, \" (\", round(percent_with_posts, 2), \"%)\")\n\n[1] \"Cuentas con publicaciones: 419 (72.74%)\"\n\npaste0(\"Cuentas sin publicaciones: \", count_no_posts, \" (\", round(percent_no_posts, 2), \"%)\")\n\n[1] \"Cuentas sin publicaciones: 157 (27.26%)\"\n\n\nTenemos muchas cuentas sin publicaciones teniendo en cuenta que Instagram se usa principalmente para publicar…\nVamos a ver la media de publicaciones quitando las cuentas sin publicaciones y los outliers que tienen más de 1000 publicaciones:\n\ncuentas_menos_1000_posts &lt;- dataset %&gt;%\n  filter(X.posts &gt; 0 & X.posts &lt;= 1000)\n\npaste0(\"Media: \", round(mean(cuentas_menos_1000_posts$X.posts), 2))\n\n[1] \"Media: 106.52\"\n\n\n\n\n2.5.6 X.followers\nRepresenta el número de seguidores que tiene una cuenta de Instagram.\n\nstr(dataset$X.followers)\n\n int [1:576] 1000 2740 159 414 151 669987 122 1078 1824 12945 ...\n\n\n\nsummary(dataset$X.followers)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n       0       39      150    85307      716 15338538 \n\n\nVolvemos a tener una media mucho más alta que la mediana. Esta variable tiene un rango de valores muy disperso.\n\ncuentas_con_seguidores &lt;- sum(dataset$X.followers &gt; 0)\ncuentas_sin_seguidores &lt;- sum(dataset$X.followers == 0)\n\npercent_con_seguidores &lt;- (cuentas_con_seguidores / total_count) * 100\npercent_sin_seguidores &lt;- (cuentas_sin_seguidores / total_count) * 100\n\npaste0(\"Cuentas con seguidores: \", cuentas_con_seguidores, \" (\", round(percent_con_seguidores, 2), \"%)\")\n\n[1] \"Cuentas con seguidores: 558 (96.88%)\"\n\npaste0(\"Cuentas sin seguidores: \", cuentas_sin_seguidores, \" (\", round(percent_sin_seguidores, 2), \"%)\")\n\n[1] \"Cuentas sin seguidores: 18 (3.12%)\"\n\n\nObservamos que hay muy pocas cuentas sin seguidores.\nVamos a ver la media de seguidores quitando las cuentas sin seguidores y las cuentas que tienen más de 10000 seguidores.\n\ncuentas_filtradas_seguidores &lt;- dataset %&gt;%\n  filter(X.followers &gt; 0 & X.followers &lt;= 10000)\n\npaste0(\"Media: \", round(mean(cuentas_filtradas_seguidores$X.followers), 2))\n\n[1] \"Media: 545.35\"\n\n\n\n\n2.5.7 X.follows\nRepresenta el número de personas que sigue una cuenta de Instagram.\n\nstr(dataset$X.follows)\n\n int [1:576] 955 533 98 651 126 150 177 76 2713 813 ...\n\n\n\nsummary(dataset$X.follows)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0    57.5   229.5   508.4   589.5  7500.0 \n\n\nEn este caso la media y la mediana no están tan alejadas como en los otros casos.\n\ncuentas_con_seguidos &lt;- sum(dataset$X.followers &gt; 0)\ncuentas_sin_seguidos &lt;- sum(dataset$X.followers == 0)\n\npercent_con_seguidos &lt;- (cuentas_con_seguidores / total_count) * 100\npercent_sin_seguidos &lt;- (cuentas_sin_seguidores / total_count) * 100\n\npaste0(\"Cuentas con seguidos: \", cuentas_con_seguidos, \" (\", round(percent_con_seguidos, 2), \"%)\")\n\n[1] \"Cuentas con seguidos: 558 (96.88%)\"\n\npaste0(\"Cuentas sin seguidos: \", cuentas_sin_seguidos, \" (\", round(percent_sin_seguidos, 2), \"%)\")\n\n[1] \"Cuentas sin seguidos: 18 (3.12%)\"\n\n\nObservamos que hay muy pocas cuentas sin seguidos. Vamos a ver si las cuentas que no siguen a nadie son las mismas que tampoco tienen seguidores:\n\ncuentas_sin_seguidos_ni_seguidores &lt;- dataset %&gt;% \n  filter(X.followers == 0 & X.follows == 0)\n\nnrow(cuentas_sin_seguidos_ni_seguidores)\n\n[1] 3\n\n\nPues resulta ser que no, solo hay 3 cuentas que no tienen ni seguidores ni seguidos."
  },
  {
    "objectID": "exploratory_analysis.html#relaciones-entre-variables",
    "href": "exploratory_analysis.html#relaciones-entre-variables",
    "title": "2  Análisis exploratorio de datos",
    "section": "2.6 Relaciones entre variables",
    "text": "2.6 Relaciones entre variables\nMatriz de correlación entre variables binarias y no binarias\n\ncor_bin_nonbin &lt;- cor(dataset[, c(binary_vars, rownames(non_binary))])\ncorrplot(cor_bin_nonbin, method=\"circle\", type=\"upper\", tl.col=\"black\", tl.srt=45)\n\n\n\n\nEstadísticas descriptivas comparativas entre cuentas falsas y reales\n\nfake_stats &lt;- sapply(dataset[dataset$fake == 1, rownames(non_binary)], \n                     function(x) c(round(mean(x), 2), median(x), round(sd(x), 2)))\nreal_stats &lt;- sapply(dataset[dataset$fake == 0, rownames(non_binary)], \n                     function(x) c(round(mean(x), 2), median(x), round(sd(x), 2)))\n\ncomparison_stats &lt;- data.frame(Fake = fake_stats, Real = real_stats)\nrownames(comparison_stats) &lt;- c(\"Media\", \"Mediana\", \"Desviación típica\")\nt(comparison_stats)\n\n                              Media Mediana Desviación típica\nFake.fullname.words            1.15     1.0              0.68\nFake.nums.length.fullname      0.07     0.0              0.17\nFake.nums.length.username      0.29     0.3              0.23\nFake.description.length        5.26     0.0             20.29\nFake.X.posts                   8.93     0.0             28.01\nFake.X.followers             110.59    40.0            318.41\nFake.X.follows               302.17    70.0            705.06\nReal.fullname.words            1.77     2.0              1.25\nReal.nums.length.fullname      0.01     0.0              0.03\nReal.nums.length.username      0.04     0.0              0.09\nReal.description.length       39.98    27.0             42.79\nReal.X.posts                 206.05    74.0            550.95\nReal.X.followers          170503.89   661.5        1282598.58\nReal.X.follows               714.60   431.0           1051.60\n\n\nLa tabla proporciona una comparación entre las estadísticas descriptivas de las cuentas falsas y reales en Instagram.\nObservamos que, en promedio, las cuentas falsas tienden a tener menos palabras en el nombre completo y una longitud de descripción más corta en comparación con las cuentas reales.\nAdemás, las cuentas falsas muestran un número significativamente menor de seguidores y personas seguidas en comparación con las cuentas reales, como indican las medias y medianas mucho más bajas en estas variables.\nPor otro lado, las diferencias en las desviaciones estándar sugieren una mayor variabilidad en el número de seguidores y personas seguidas para las cuentas reales en comparación con las falsas."
  },
  {
    "objectID": "exploratory_analysis.html#cuestiones-generales",
    "href": "exploratory_analysis.html#cuestiones-generales",
    "title": "2  Análisis exploratorio de datos",
    "section": "2.7 Cuestiones generales",
    "text": "2.7 Cuestiones generales\nVamos a explorar una serie de cuestiones generales acerca de nuestros datos, para entender mejor como se distribuyen nuestros datos y explorar relaciones interesantes:\n\n¿Cuál es la proporción de perfiles privados con foto de perfil?\n\n\nprop.table(table(\n  ifelse(dataset$private == 1, \"Privada\", \"Publica\"), \n  ifelse(dataset$profile.pic == 1, \"Con foto\", \"Sin foto\")))\n\n         \n            Con foto   Sin foto\n  Privada 0.29340278 0.08854167\n  Publica 0.40798611 0.21006944\n\n\nLo más común es tener una cuenta pública y con foto\n\n¿Cuál es la media de seguidores de los perfiles falsos frente a los públicos?\n\n\nmedias &lt;- dataset %&gt;% \n  group_by(fake) %&gt;% \n  summarise(mean(X.followers))\n\ndata.frame(\n  Perfil=c(\"Real\", \"Falso\"),\n  \"Media de seguidores\"=medias$`mean(X.followers)`)\n\n  Perfil Media.de.seguidores\n1   Real         170503.8854\n2  Falso            110.5868\n\n\n\n¿Existe una correlación entre la longitud de la descripción y la cantidad de seguidores?\n\n\ncor(as.numeric(dataset$description.length), as.numeric(dataset$X.followers))\n\n[1] 0.005929455\n\n\nParece ser que no.\n\n¿Cuál es la media del número de publicaciones según si el perfil es privado o no?\n\n\nmedias &lt;- dataset %&gt;% \n  group_by(private) %&gt;% \n  summarise(mean(X.posts))\n\ndata.frame(\n  Cuenta=c(\"Pública\", \"Privada\"),\n  \"Media de publicaciones\"=medias$`mean(X.posts)`)\n\n   Cuenta Media.de.publicaciones\n1 Pública              135.11798\n2 Privada               62.78182\n\n\n\n¿Cuál es la proporción de perfiles con más de 1000 seguidores falsos frente a los reales?\n\n\ntable(dataset$fake, \n      dataset$X.followers &gt; 1000) / rowSums(table(dataset$fake, \n                                                  dataset$X.followers &gt; 1000))\n\n   \n         FALSE       TRUE\n  0 0.64236111 0.35763889\n  1 0.98263889 0.01736111\n\n\nEl 98.26% de las cuentas falsas tienen menos de 1000 seguidores. El 35.7% de las cuentas reales tienen más de 1000 seguidores.\n\n¿Qué porentaje de cuentas tienen números en el nombre real, en función de perfiles falsos y reales?\n\n\nmedias &lt;- dataset %&gt;% \n  mutate(has.nums.fullname=as.numeric(nums.length.fullname &gt; 0)) %&gt;%\n  group_by(fake) %&gt;% \n  summarise(mean(has.nums.fullname))\n\ndata.frame(\n  Cuenta=c(\"Real\", \"Falso\"),\n  \"Media del ratio de números en el nombre real\"=medias$`mean(has.nums.fullname)`)\n\n  Cuenta Media.del.ratio.de.números.en.el.nombre.real\n1   Real                                   0.02777778\n2  Falso                                   0.17361111\n\n\nEl 2% de las cuentas reales tienen números en su nombre real mientras que el 17% de las cuentas falsas tienen números en el nombre real. Claramente tener números en el nombre real es algo sospechoso.\n\n¿Cuáles son las cuentas falsas con más seguidores?\n\n\nseguidores_fake &lt;- dataset %&gt;%\n  filter(fake == 1) %&gt;%\n  select(X.followers, fake) %&gt;%\n  arrange(desc(X.followers))\n\nhead(seguidores_fake)\n\n  X.followers fake\n1        3033    1\n2        3003    1\n3        2346    1\n4        1489    1\n5        1031    1\n6         864    1\n\n\nNo hay ninguna cuenta falsa con más de 3033 seguidores.\n\n¿Cuántas cuentas reales tienen más seguidores que la cuenta falsa con más seguidores?\n\n\nseguidores_real &lt;- dataset %&gt;%\n  filter(fake == 0 & X.followers &gt; seguidores_fake$X.followers[1]) %&gt;%\n  select(X.followers, fake) %&gt;%\n  arrange(desc(X.followers))\n\nhead(seguidores_real)\n\n  X.followers fake\n1    15338538    0\n2    12397719    0\n3     6741307    0\n4     5315651    0\n5     3896490    0\n6      890969    0\n\npaste0(\"Hay \", nrow(seguidores_real), \" cuentas reales con más de \", seguidores_fake$X.followers[1], \" seguidores\")\n\n[1] \"Hay 51 cuentas reales con más de 3033 seguidores\"\n\n\nInteresante, el 9% del dataset se podría directamente clasificar como cuenta real, al tener más seguidores que la cuenta falsa con más seguidores."
  },
  {
    "objectID": "exploratory_analysis.html#conclusiones",
    "href": "exploratory_analysis.html#conclusiones",
    "title": "2  Análisis exploratorio de datos",
    "section": "2.8 Conclusiones",
    "text": "2.8 Conclusiones\nCon este análisis exploratorio hemos podido entender mejor la naturaleza de nuestros datos, entendiendo mejor la distribución de los mismos y pudiendo ver las primeras relaciones entre distintas variables.\nEl carácter númerico de nuestros datos nos permitirá que técnicas como la regresión lineal nos puedan dar buenos resultados, además de que, como hemos visto, hay ciertas relaciones clave entre distintas variables que podremos explotar.\nUn buen análisis exploratorio es muy importante y puede marcar el desarrollo del estudio de nuestros datos. Hemos obtenido un conocimiento inicial que nos vendrá muy bien cuando comencemos a aplicar las primeras técnicas de análisis de datos.\nEn el siguiente apratado, visualización de datos, vamos a visualizar algunos de los puntos que hemos tratado en este análisis exploratorio, para poder hacernos un modelo mental aún más cercano a los datos."
  },
  {
    "objectID": "data_visualization.html#variables-binarias",
    "href": "data_visualization.html#variables-binarias",
    "title": "3  Visualización de datos",
    "section": "3.1 Variables binarias",
    "text": "3.1 Variables binarias\nVamos a comenzar visualizando las variables binarias, que como vimos en el análisis exploratorio son fake, profile.pic, name..username, external.URL y private.\n\n3.1.1 fake\n\nhist(dataset$fake)\n\n\n\n\nEl histograma no es lo más adecuado para visualizar variables binarias (aunque se visualiza claramente), vamos a hacer a partir de ahora los gráficos de las variables binarias con ggplot. Podemos visualizarlo con un gráfico de barras:\n\nggplot(dataset, aes(x = factor(fake))) +\n  geom_bar() +\n  labs(x = \"Cuenta falsa\", y = \"Cuentas\", \n       title = \"Cuentas de Instagram reales y falsas\") +\n  scale_x_discrete(labels = c(\"0\" = \"No falsa\", \"1\" = \"Falsa\"))\n\n\n\n\nO con un gráfico circular:\n\nfake_df &lt;- data.frame(\n  category = c(\"No falsa\", \"Falsa\"),\n  count = c(sum(dataset$fake == 0), sum(dataset$fake == 1))\n)\nggplot(fake_df, aes(x = \"\", y = count, fill = category)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  labs(title = \"Proporción de cuentas reales y falsas\", \n       fill = \"Cuenta falsa\") +\n  scale_fill_manual(values = \n                      c(\"No falsa\" = \"#FF9999\", \"Falsa\" = \"#99DDFF\"))\n\n\n\n\nEste gráfico es muy adecuado para la visualización que queremos hacer y lo usaremos en el resto de variables binarias o con pocos valores únicos.\n\n\n[1] \"Cuentas falsas: 288 (50%)\"\n\n\n[1] \"Cuentas no falsas: 288 (50%)\"\n\n\n\n\n3.1.2 profile.pic\nToma el valor 1 para las cuentas con foto de perfil y un 0 para las que no tienen.\n\nprofile_pic_df &lt;- data.frame(\n  category = c(\"No tiene\", \"Tiene\"),\n  count = c(sum(dataset$profile.pic == 0), sum(dataset$profile.pic == 1))\n)\nggplot(profile_pic_df, aes(x = \"\", y = count, fill = category)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  labs(title = \"Proporción de cuentas con y sin foto de perfil\", \n       fill = \"Foto de perfil\") +\n  scale_fill_manual(values = \n                      c(\"No tiene\" = \"#FF9999\", \"Tiene\" = \"#99DDFF\"))\n\n\n\n\n\n\n[1] \"Cuentas con foto de perfil: 404 (70.14%)\"\n\n\n[1] \"Cuentas sin foto de perfil: 172 (29.86%)\"\n\n\n\n\n3.1.3 name..username\nToma el valor 1 si el nombre de la persona es igual al username que se ha puesto en Instagram, y 0 en caso contrario.\n\nname_username_df &lt;- data.frame(\n  category = c(\"No\", \"Sí\"),\n  count = c(sum(dataset$name..username == 0), sum(dataset$name..username == 1))\n)\nggplot(name_username_df, aes(x = \"\", y = count, fill = category)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  labs(title = \"Proporción de cuentas con nombre igual a username\", \n       fill = \"Nombre igual a Username\") +\n  scale_fill_manual(values = c(\"No\" = \"#FF9999\", \"Sí\" = \"#99DDFF\"))\n\n\n\n\n\n\n[1] \"Cuentas con mismo nombre y username: 20 (3.47%)\"\n\n\n[1] \"Cuentas con distinto nombre y username: 556 (96.53%)\"\n\n\n\n\n3.1.4 external.URL\nToma el valor 1 si la cuenta tiene un enlace en el perfil, y 0 si no tiene.\n\nexternal_url_df &lt;- data.frame(\n  category = c(\"No tiene\", \"Tiene\"),\n  count = c(sum(dataset$external.URL == 0), sum(dataset$external.URL == 1))\n)\nggplot(external_url_df, aes(x = \"\", y = count, fill = category)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  labs(title = \"Proporción de cuentas con y sin enlace en el perfil\", \n       fill = \"Enlace en el perfil\") +\n  scale_fill_manual(values = c(\"No tiene\" = \"#FF9999\", \"Tiene\" = \"#99DDFF\"))\n\n\n\n\n\n\n[1] \"Cuentas con enlace en el perfil: 67 (11.63%)\"\n\n\n[1] \"Cuentas sin enlace en el perfil: 509 (88.37%)\"\n\n\n\n\n3.1.5 private\nToma el valor 1 si la cuenta es privada, y 0 si es pública.\n\nprivate_df &lt;- data.frame(\n  category = c(\"Pública\", \"Privada\"),\n  count = c(sum(dataset$private == 0), sum(dataset$private == 1))\n)\nggplot(private_df, aes(x = \"\", y = count, fill = category)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  labs(title = \"Proporción de cuentas públicas y privadas\", fill = \"Cuenta privada\") +\n  scale_fill_manual(values = c(\"Pública\" = \"#FF9999\", \"Privada\" = \"#99DDFF\"))\n\n\n\n\n\n\n[1] \"Cuentas privadas: 220 (38.19%)\"\n\n\n[1] \"Cuentas públicas: 356 (61.81%)\""
  },
  {
    "objectID": "data_visualization.html#variables-no-binarias",
    "href": "data_visualization.html#variables-no-binarias",
    "title": "3  Visualización de datos",
    "section": "3.2 Variables no binarias",
    "text": "3.2 Variables no binarias\nComo vimos en el análisis exploratorio, las variables no binarias son fullname.words, nums.length.fullname, nums.length.username, description.length, X.posts, X.followers y X.follows.\n\n3.2.1 fullname.words\nRepresenta el número de palabras en el nombre completo del usuario.\n\nggplot(dataset, aes(x = fullname.words)) +\n  geom_histogram(binwidth = 1, fill = \"#99DDFF\", color = \"black\", alpha = 0.7) +\n  labs(x = \"Longitud de Descripción\", y = \"Palabras\", \n       title = \"Número de palabras en el nombre completo\")\n\n\n\n\nGráfico circular:\n\nfullname_words_df &lt;- as.data.frame(table(dataset$fullname.words))\nggplot(fullname_words_df, aes(x = \"\", y = Freq, fill = Var1)) +\n  geom_bar(stat = \"identity\", width = 1) +\n  coord_polar(\"y\", start = 0) +\n  theme_void() +\n  labs(title = \"Número de palabras en el nombre completo\", fill = \"Palabras\")\n\n\n\n\n\n\n[1] \"Cuentas sin nombre completo: 57 (9.9%)\"\n\n\n[1] \"Cuentas con nombre completo de una palabra: 283 (49.13%)\"\n\n\n[1] \"Cuentas con nombre de más de una palabra: 236 (40.97%)\"\n\n\n\n\n3.2.2 nums.length.fullname\nRatio del número de carácteres númericos en el nombre completo respecto a la longitud del nombre completo.\n\nggplot(dataset, aes(x = nums.length.fullname)) +\n  geom_histogram(bins = 10, fill = \"#99DDFF\", color = \"black\", alpha = 0.7) + \n  labs(x = \"Ratio de números en el nombre Completo\", y = \"Frecuencia\", \n       title = \"Histograma del ratio de números en el nombre Completo\")\n\n\n\n\nVeamos el gráfico de densidad:\n\nggplot(dataset, aes(x = nums.length.fullname)) +\n  geom_density(fill = \"#99DDFF\", alpha = 0.7) +\n  labs(x = \"Ratio de números en el nombre Completo\", \n       y = \"Densidad\", title = \n         \"Gráfico de densidad del ratio de números en el nombre Completo\")\n\n\n\n\nVeamos la cantidad de cuentas con y sin números en el nombre completo.\n\ncount_summary &lt;- data.frame(\n  Categoria = c(\"Tiene\", \"No tiene\"),\n  Cantidad = c(count_with_numbers, count_no_numbers)\n)\n\n# Gráfico de barras\nggplot(count_summary, aes(x = Categoria, y = Cantidad, fill = Categoria)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Numeros en el nombre completo\",\n    y = \"Cantidad de cuentas\",\n    title = \"Cuentas con y sin números en el nombre completo\"\n  ) +\n  scale_fill_manual(values = c(\"Tiene\" = \"#FF9999\", \"No tiene\" = \"#99DDFF\"))\n\n\n\n\n\n\n[1] \"Cuentas con números en el nombre completo: 58 (10.07%)\"\n\n\n[1] \"Cuentas sin números en el nombre completo: 518 (89.93%)\"\n\n\n\n\n3.2.3 nums.length.username\nRatio del número de carácteres númericos en el nombre de usuario respecto a la longitud del nombre de usuario.\nVisualizamos:\n\nggplot(dataset, aes(x = nums.length.username)) +\n  geom_histogram(bins = 10, fill = \"#99DDFF\", color = \"black\", alpha = 0.7) + \n  labs(x = \"Ratio de números en el nombre de usuario\", y = \"Frecuencia\", \n       title = \"Histograma del ratio de números en el nombre de usuario\")\n\n\n\n\nVeamos el gráfico de densidad:\n\nggplot(dataset, aes(x = nums.length.username)) +\n  geom_density(fill = \"#99DDFF\", alpha = 0.7) +\n  labs(x = \"Ratio de números en el nombre de usuario\", \n       y = \"Densidad\", title = \n         \"Gráfico de densidad del ratio de números en el nombre de usuario\")\n\n\n\n\nVeamos la cantidad de cuentas con y sin números en el nombre completo.\n\ncount_summary &lt;- data.frame(\n  Categoria = c(\"Tiene\", \"No tiene\"),\n  Cantidad = c(count_with_numbers, count_no_numbers)\n)\n\n# Gráfico de barras\nggplot(count_summary, aes(x = Categoria, y = Cantidad, fill = Categoria)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Numeros en el nombre de usuario\",\n    y = \"Cantidad de cuentas\",\n    title = \"Cuentas con y sin números en el nombre de usuario\"\n  ) +\n  scale_fill_manual(values = c(\"Tiene\" = \"#FF9999\", \"No tiene\" = \"#99DDFF\"))\n\n\n\n\n\n\n[1] \"Cuentas con números en el nombre completo: 277 (48.09%)\"\n\n\n[1] \"Cuentas sin números en el nombre completo: 299 (51.91%)\"\n\n\n\n\n3.2.4 description.length\nLa longitud de la descripción de la cuenta de Instagram.\n\nggplot(dataset, aes(x = description.length)) +\n  geom_histogram(bins = 10, fill = \"#99DDFF\", color = \"black\", alpha = 0.7) + \n  labs(x = \"Número de carácteres en la descripción\", y = \"Frecuencia\", \n       title = \"Histograma de la longitud de la descripción\")\n\n\n\n\nSe observa claramente que hay muchas cuentas que prácticamente no tienen carácteres en la descripción.\n\ncount_summary &lt;- data.frame(\n  Categoria = c(\"Tiene\", \"No tiene\"),\n  Cantidad = c(count_with_description, count_no_description)\n)\n\nggplot(count_summary, aes(x = Categoria, y = Cantidad, fill = Categoria)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Descripción\",\n    y = \"Cantidad de cuentas\",\n    title = \"Cuentas con y sin descripción\"\n  ) +\n  scale_fill_manual(values = c(\"No tiene\" = \"#FF9999\", \"Tiene\" = \"#99DDFF\"))\n\n\n\n\n\n\n[1] \"Cuentas con descripción: 250 (43.4%)\"\n\n\n[1] \"Cuentas sin descripción: 326 (56.6%)\"\n\n\n\n\n3.2.5 X.posts\nRepresenta el número de publicaciones que tiene una cuenta de Instagram.\n\nggplot(dataset, aes(x = X.posts)) +\n  geom_histogram(bins = 10, fill = \"#99DDFF\", color = \"black\", alpha = 0.7) + \n  labs(x = \"Número de publicaciones\", y = \"Frecuencia\", \n       title = \"Histograma del número de publicaciones\")\n\n\n\n\nEl rango de valores es muy muy amplio y hay mucha concentración en los valores bajos, tenemos que visualizarlo de otra manera, vamos a ver el gráfico de densidad:\n\nggplot(dataset, aes(x = X.posts)) +\n  geom_density(fill = \"#99DDFF\", alpha = 0.7) +\n  labs(x = \"Número de publicaciones\", y = \"Densidad\", \n       title = \"Gráfico de densidad del número de publicaciones\")\n\n\n\n\nLos valores únicos que tenemos con miles de publicaciones hacen que el gráfico no se pueda visualizar bien. Vamos a realizar el gráfico de nuevo eliminando las cuentas con más de 1000 publicaciones y la cuentas con 0 publicaciones:\n\ncuentas_menos_1000_posts &lt;- dataset %&gt;%\n  filter(X.posts &gt; 0 & X.posts &lt;= 1000)\n\nggplot(cuentas_menos_1000_posts, aes(x = X.posts)) +\n  geom_density(fill = \"#99DDFF\", alpha = 0.7) +\n  labs(x = \"Número de publicaciones\", y = \"Densidad\", \n       title = \"Gráfico de densidad del número de publicaciones\")\n\n\n\n\nAhora se observa el gráfico mejor, y vemos que la mayoría de cuentas tienen menos de 125 publicaciones.\n\ncount_summary &lt;- data.frame(\n  Categoria = c(\"Tiene\", \"No tiene\"),\n  Cantidad = c(count_with_posts, count_no_posts)\n)\n\n# Gráfico de barras\nggplot(count_summary, aes(x = Categoria, y = Cantidad, fill = Categoria)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Publicaciones\",\n    y = \"Cantidad de cuentas\",\n    title = \"Cuentas con publicaciones y sin publicaciones\"\n  ) +\n  scale_fill_manual(values = c(\"No tiene\" = \"#FF9999\", \"Tiene\" = \"#99DDFF\"))\n\n\n\n\n\n\n[1] \"Cuentas con publicaciones: 419 (72.74%)\"\n\n\n[1] \"Cuentas sin publicaciones: 157 (27.26%)\"\n\n\n\n\n3.2.6 X.followers\nRepresenta el número de seguidores que tiene una cuenta de Instagram.\n\nggplot(dataset, aes(x = X.followers)) +\n  geom_histogram(bins = 10, fill = \"#99DDFF\", color = \"black\", alpha = 0.7) + \n  labs(x = \"Número de seguidores\", y = \"Frecuencia\", \n       title = \"Histograma del número de seguidores\")\n\n\n\n\nPrácticamente no se ve nada. Vamos a eliminar las cuentas con más de 10000 seguidores y con 0 seguidores.\n\ncuentas_filtradas_seguidores &lt;- dataset %&gt;%\n  filter(X.followers &gt; 0 & X.followers &lt; 10000)\n\nggplot(cuentas_filtradas_seguidores, aes(x = X.followers)) +\n  geom_density(fill = \"#99DDFF\", alpha = 0.7) +\n  labs(x = \"Número de seguidores\", y = \"Densidad\", \n       title = \"Gráfico de densidad del número de seguidores\")\n\n\n\n\nLa mayoría de cuentas tienen menos de 1000 seguidores.\n\ncount_summary &lt;- data.frame(\n  Categoria = c(\"Tiene\", \"No tiene\"),\n  Cantidad = c(cuentas_con_seguidores, cuentas_sin_seguidores)\n)\n\nggplot(count_summary, aes(x = Categoria, y = Cantidad, fill = Categoria)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Seguidores\",\n    y = \"Cantidad de cuentas\",\n    title = \"Cuentas con seguidores y sin seguidores\"\n  ) +\n  scale_fill_manual(values = c(\"No tiene\" = \"#FF9999\", \"Tiene\" = \"#99DDFF\"))\n\n\n\n\n\n\n[1] \"Cuentas con seguidores: 558 (96.88%)\"\n\n\n[1] \"Cuentas sin seguidores: 18 (3.12%)\"\n\n\n\n\n3.2.7 x.follows\nRepresenta el número de personas que sigue una cuenta de Instagram.\n\nggplot(dataset, aes(x = X.follows)) +\n  geom_histogram(bins = 10, fill = \"#99DDFF\", color = \"black\", alpha = 0.7) + \n  labs(x = \"Número de seguidos\", y = \"Frecuencia\", \n       title = \"Histograma del número de seguidos\")\n\n\n\n\nLa mayoría de cuentas siguen a menos de 1500 personas.\n\ncount_summary &lt;- data.frame(\n  Categoria = c(\"Tiene\", \"No tiene\"),\n  Cantidad = c(cuentas_con_seguidos, cuentas_sin_seguidos)\n)\n\nggplot(count_summary, aes(x = Categoria, y = Cantidad, fill = Categoria)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"Seguidos\",\n    y = \"Cantidad de cuentas\",\n    title = \"Cuentas con seguidos y sin seguidos\"\n  ) +\n  scale_fill_manual(values = c(\"No tiene\" = \"#FF9999\", \"Tiene\" = \"#99DDFF\"))\n\n\n\n\n\n\n[1] \"Cuentas con seguidos: 558 (96.88%)\"\n\n\n[1] \"Cuentas sin seguidos: 18 (3.12%)\""
  },
  {
    "objectID": "data_visualization.html#análisis-multivariado",
    "href": "data_visualization.html#análisis-multivariado",
    "title": "3  Visualización de datos",
    "section": "3.3 Análisis multivariado",
    "text": "3.3 Análisis multivariado\nVamos a crear algunos gráficos interesantes que relacionen distintas variables entre sí:\n\nRelación entre si la cuenta es falsa y si tiene foto de perfil\n\n\nggplot(dataset, aes(x = factor(profile.pic), fill = factor(fake))) +\n  geom_bar(position = \"fill\") +\n  labs(x = \"Foto de perfil\", y = \"Proporción\", fill = \"Cuenta falsa\",\n       title = \"Proporción de cuentas falsas según tengan foto de perfil\") +\n  scale_x_discrete(labels = c(\"0\" = \"No tiene\", \"1\" = \"Tiene\")) +\n  scale_fill_manual(values = c(\"0\" = \"#99DDFF\", \"1\" = \"#FF9999\"))\n\n\n\n\nSe observa que la gran mayoria de cuentas que no tienen foto de perfil, son falsas, mientras que para las cuentas con foto de perfil, la mayoría son reales, aunque con una proporción mucho más cercana al punto medio.\n\nRelación entre la longitud de la descripción y el número de seguidores\n\n\nggplot(dataset, aes(x = description.length, y = X.followers)) +\n  geom_point(alpha = 0.5, color = \"#FF9999\") +\n  geom_smooth(method = \"lm\", color = \"blue\") +\n  labs(x = \"Longitud de la descripción\", y = \"Número de seguidores\",\n       title = \"Relación entre la longitud de la descripción y el número de seguidores\") +\n  scale_y_log10()\n\n\n\n\nObservamos una interesante relación entre el número de seguidores y la longitud de la descripción. Sin la escala logarítmica no se apreciaría nada. Parece ser que a más larga la descripción, más famosa es la cuenta. No parece algo extremadamente relevante, ya que tenemos un límite de longitud de descripción en las cuentas de Instagram, pero si tiene cierto sentido que una cuenta famosa albergue más información en la descripción que una cuenta normal.\n\nDistribución de la longitud de la descripción según si la cuenta es privada o pública\n\n\nggplot(dataset, aes(x = description.length, fill = factor(private))) +\n  geom_density(alpha = 0.6) +\n  labs(x = \"Longitud de la descripción\", y = \"Densidad\", fill = \"Cuenta privada\") +\n  scale_fill_manual(values = c(\"0\" = \"#FF9999\", \"1\" = \"#99DDFF\")) +\n  theme_minimal() +\n  labs(title = \"Distribución de la longitud de la descripción según privacidad de la cuenta\")\n\n\n\n\nLas cuentas públicas suelen tener más descripción.\n\nRelación entre el número de seguidores y el número de seguidos\n\n\nggplot(dataset, aes(x = X.follows, y = X.followers)) +\n  geom_point(alpha = 0.5, color = \"#99DDFF\") +\n  geom_smooth(method = \"lm\", color = \"#FF9999\") +\n  labs(x = \"Número de seguidos\", y = \"Número de seguidores\") +\n  theme_minimal() +\n  labs(title = \"Relación entre el número de seguidores y seguidos\") +\n  scale_y_log10()\n\n\n\n\nNo parece que haya relación predecible entre los seguidos y los seguidores.\n\nHistogramas de variables no binarias\n\n\nnumeric_vars &lt;- dataset %&gt;% \n  select(nums.length.username, fullname.words, nums.length.fullname, \n         description.length, X.posts, X.followers, X.follows)\n\nnumeric_vars %&gt;% \n  gather(key = \"variable\", value = \"value\") %&gt;%\n  ggplot(aes(x = value)) +\n  geom_histogram(bins = 30, fill = \"skyblue\", color = \"black\") +\n  facet_wrap(~ variable, scales = \"free\") +\n  labs(title = \"Distribución de Variables Numéricas\")\n\n\n\n\nTodas siguen una distribución parecida, independientemente de que signifiquen cosas totalmente distintas, suelen concentrarse en su mayoría, cerca del 0. Esto probablemente se deba a que los más fácil de conseguir para estas variables en Instagram, sea 0, independientemente de lo que signifiquen.\n\ndataset &lt;- dataset %&gt;%\n  mutate(posts_category = cut(X.posts, breaks = c(-1, 10, 50, 100, 500, 1000, Inf),\n                              labels = c(\"0-10\", \"11-50\", \n                                         \"51-100\", \"101-500\", \n                                         \"501-1000\", \"&gt;1000\")))\n\nggplot(dataset, aes(x = posts_category, fill = factor(fake))) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"0\" = \"#99DDFF\", \"1\" = \"#FF9999\")) +\n  labs(x = \"Número de publicaciones\", y = \"Proporción\",\n       title = \"Proporción de cuentas falsas según número de publicaciones\",\n       fill = \"Cuenta falsa\") +\n  theme_minimal()\n\n\n\n\nNo hay cuentas falsas con más de 500 publicaciones realizadas."
  },
  {
    "objectID": "data_visualization.html#conclusiones",
    "href": "data_visualization.html#conclusiones",
    "title": "3  Visualización de datos",
    "section": "3.4 Conclusiones",
    "text": "3.4 Conclusiones\nLa visualización de datos nos ha permitido entender mejor la distribución y las relaciones entre las variables del dataset. Utilizando la librería ggplot2, hemos creado gráficos claros y efectivos para variables binarias y no binarias. Los histogramas y gráficos circulares han facilitado la identificación de patrones y proporciones. En el análisis multivariado, hemos observado correlaciones relevantes, como la relación entre cuentas falsas y la presencia de foto de perfil. Estas visualizaciones no solo enriquecen el análisis exploratorio, sino que también sirven como base sólida para futuros modelos predictivos y toma de decisiones informadas."
  },
  {
    "objectID": "association_rules.html#pre-processing",
    "href": "association_rules.html#pre-processing",
    "title": "4  Reglas de asociación",
    "section": "4.1 Pre-processing",
    "text": "4.1 Pre-processing\nRecordamos del apartado de análisis exploratorio que teníamos:\n\nVariables binarias:\n\nprofile.pic\nname..username\nexternal.URL\nprivate\nfake\n\nVariables no binarias:\n\nnums.length.username\nfullname.words\nnums.length.fullname\ndescription.length\nX.posts\nX.followers\nX.follows\n\n\n\n4.1.1 Variables binarias\nLas añadimos directamente al dataset modificado que vamos a ir construyendo\n\ndatarules &lt;- transmute(dataset, \n                       profile.pic=profile.pic, \n                       name..username=name..username,\n                       external.URL=external.URL,\n                       private=private,\n                       fake=fake)\n\n\n\n4.1.2 Variables no binarias\nPara las variables no binarias, podemos tener distintos puntos de vista, así que vamos a ir viendo cada variable:\n\n4.1.2.1 nums.length.username\nEl ratio de números en el nombre de usuario de la cuenta es díficilmente binarizable, ya que no es trivial donde poner el punto medio. En el nombre de persona si resulta extraño tener números, pero en el nombre de usuario puede ser normal, no tiene porque estar relacionado directamente con que la cuenta sea falsa.\nPodríamos binarizar simplemente en “tiene números o no tiene números”, ya que como vimos en el análisis exploratorio, teníamos prácticamente un 50-50, pero eso no exprimiría todo el conocimiento de los datos, pues lo que viene a representar esta variable es el ratio de carácteres númericos sobre la longitud del nombre.\nVamos a discretizar en 3 categorías:\n\n“0”\n“(0, 0.5]”\n“(0.5, 1]”\n\n\nlu_discretize &lt;- transmute(dataset, \n          nums.length.username=\n            ifelse(nums.length.username == 0, \n                   \"0\", ifelse(nums.length.username &lt;= 0.5, \n                               \"(0, 0.5]\", \"(0.5, 1]\")))\n\ndatarules &lt;- mutate(datarules, \n       nums.length.username=lu_discretize$nums.length.username)\n\n\n\n4.1.2.2 nums.length.fullname\nPara esta variable, si vamos a binarizar, ya que no es lo normal tener un número en el nombre completo. Pondremos un 0 a las cuenas que no tengan números en el nombre completo y un 1 a las que si tengan,\n\nlfn_binary &lt;- transmute(dataset, \n                        nums.length.fullname=\n                          as.numeric(nums.length.fullname!=0))\n\ndatarules &lt;- mutate(datarules, \n       has.nums.fullname=lfn_binary$nums.length.fullname)\n\n\n\n4.1.2.3 fullname.words\nPara esta variable vamos a tomar una decisión que quizá no guste a todos los lectores, pero creemos que dará los mejores resultados (recordamos que esta variable representa el número de palabras en el nombre completo)\n\ntable(dataset$fullname.words)\n\n\n  0   1   2   3   4   5   6  10  12 \n 57 283 187  34   7   4   2   1   1 \n\n\nTener 0 palabras en el nombre no es lo normal, tener entre 1 y 2, lo es, tener 3 o más tampoco es normal. Esto obviamente subjetivo y está basado en la opinión subjetiva del escritor de este libro en base a su experiencia en el uso de Instagram.\nVamos a categorizar esta varaible en 3 rangos:\n\n“0”\n“[1, 2]”\n“&gt; 2”\n\n\nfnw_discretize &lt;- transmute(dataset, \n         fullname.words =\n            ifelse(fullname.words == 0, \n                   \"0\", ifelse(fullname.words &lt;= 2, \n                               \"[1, 2]\", \"&gt; 2\")))\n\ndatarules &lt;- mutate(datarules, \n       fullname.words=fnw_discretize$fullname.words)\n\n\n\n4.1.2.4 description.length\nVamos a binarizar esta variable, en el análisis exploratorio vimos que había mas cuentas sin descripción que con descripción y esto puede ser interesante.\n\ndl_binary &lt;- transmute(dataset, \n                        description.length=\n                          as.numeric(description.length!=0))\n\ndatarules &lt;- mutate(datarules, \n       has.description=dl_binary$description.length)\n\n\n\n4.1.2.5 X.posts\nPara esta variable pasaremos a 3 categorías, ya que creemos que dividen bien el conjunto de valores:\n\n\n[1] \"Cuentas sin publicaciones: 157\"\n\n\n[1] \"Cuentas con entre 0 y 100 publicaciones: 292\"\n\n\n[1] \"Cuentas con más de 100 publicaciones: 576\"\n\n\nPor tanto estas categorías son:\n\n“0”\n“(0, 100]”\n“&gt; 100”\n\n\np_discretize &lt;- transmute(dataset, \n         X.posts =\n            ifelse(X.posts == 0, \n                   \"0\", ifelse(X.posts &lt;= 100, \n                               \"(0, 100]\", paste0(\"&gt; 100\"))))\n\ndatarules &lt;- mutate(datarules, \n       X.posts=p_discretize$X.posts)\n\n\n\n4.1.2.6 X.followers\nVamos a dividir de nuevo en 3 categorías que hemos considerado:\n\n\n[1] \"Cuentas con menos de 20 seguidores: 95\"\n\n\n[1] \"Cuentas con entre 20 y 200 seguidores: 223\"\n\n\n[1] \"Cuentas con más de 200 seguidores: 258\"\n\n\nPor tanto estas categorías son:\n\n“&lt; 20”\n“[20, 200]”\n“&gt; 200”\n\n\nfwrs_discretize &lt;- transmute(dataset, \n         X.followers =\n            ifelse(X.followers &lt; 20, \n                   \"&lt; 20\", ifelse(X.followers &lt;= 200, \n                               \"[20, 200]\", paste0(\"&gt; 200\"))))\n\ndatarules &lt;- mutate(datarules, \n       X.followers=fwrs_discretize$X.followers)\n\n\n\n4.1.2.7 X.follows\nPara los seguidos vamos a dividir en las mismas categorías que para los seguidores:\n\n\n[1] \"Cuentas con menos de 20 seguidos: 64\"\n\n\n[1] \"Cuentas con entre 20 y 200 seguidos: 211\"\n\n\n[1] \"Cuentas con más de 200 seguidos: 301\"\n\n\nPor tanto estas categorías son:\n\n“&lt; 20”\n“[20, 200]”\n“&gt; 200”\n\n\nfws_discretize &lt;- transmute(dataset, \n         X.follows =\n            ifelse(X.follows &lt; 20, \n                   \"&lt; 20\", ifelse(X.follows &lt;= 200, \n                               \"[20, 200]\", paste0(\"&gt; 200\"))))\n\ndatarules &lt;- mutate(datarules, \n       X.follows=fws_discretize$X.follows)\n\n\n\n\n4.1.3 Resultados del pre-processing\nPor tanto, después de nuestro preprocessing, nos quedan como variables de nuestro dataset:\n\nprofile.pic\n\nVariable binaria que toma el valor 1 si la cuenta tiene foto de perfil, 0 si no tiene.\n\nname..username\n\nVariable binaria que toma el valor 1 si el nombre completo de la persona y el de usuario es el mismo, 0 si no.\n\nexternal.URL\n\nVariable binaria que toma el valor 1 si la cuenta tiene un enlace puesto en su perfil, 0 si no.\n\nprivate\n\nVariable binaria que toma el valor 1 si la cuenta es privada, 0 si es pública.\n\nnums.length.username\n\nVariable trinaria que toma los valores:\n\n“0” si no tiene números en el nombre de usuario.\n“(0, 0.5]” si el ratio de números es mayor a 0 y menor o igual a 0.5.\n“(0.5, 1]” si el ratio de números es mayor a 0.5 y menor o igual a 1.\n\n\nhas.nums.fullname\n\nVariable binaria que toma el valor 1 si el nombre completo contiene números, 0 si no contiene.\n\nfullname.words\n\nVariable categórica que toma los valores:\n\n“0” si el nombre completo no tiene palabras.\n“[1, 2]” si el nombre completo tiene entre 1 y 2 palabras.\n“&gt; 2” si el nombre completo tiene más de 2 palabras.\n\n\nhas.description\n\nVariable binaria que toma el valor 1 si la cuenta tiene una descripción, 0 si no tiene.\n\nX.posts\n\nVariable categórica que toma los valores:\n\n“0” si la cuenta no tiene publicaciones.\n“(0, 100]” si la cuenta tiene entre 1 y 100 publicaciones.\n“&gt; 100” si la cuenta tiene más de 100 publicaciones.\n\n\nX.followers\n\nVariable categórica que toma los valores:\n\n“&lt; 20” si la cuenta tiene menos de 20 seguidores.\n“[20, 200]” si la cuenta tiene entre 20 y 200 seguidores.\n“&gt; 200” si la cuenta tiene más de 200 seguidores.\n\n\nX.follows\n\nVariable categórica que toma los valores:\n\n“&lt; 20” si la cuenta sigue a menos de 20 cuentas.\n“[20, 200]” si la cuenta sigue a entre 20 y 200 cuentas.\n“&gt; 200” si la cuenta sigue a más de 200 cuentas.\n\n\nfake\n\nVariable binaria que toma el valor 1 si la cuenta es falsa, 0 si no lo es.\n\n\nCon este nuevo dataset binarizado y discretizado, estamos listos para proceder al análisis de reglas de asociación utilizando el paquete arules en R. Este preprocesamiento nos asegura que las variables están en un formato adecuado para el análisis, lo que facilitará la identificación de patrones y asociaciones significativas."
  },
  {
    "objectID": "association_rules.html#generando-reglas",
    "href": "association_rules.html#generando-reglas",
    "title": "4  Reglas de asociación",
    "section": "4.2 Generando reglas",
    "text": "4.2 Generando reglas\nNuestro dataset ha quedado así:\n\n\n'data.frame':   576 obs. of  12 variables:\n $ profile.pic         : int  1 1 1 1 1 1 1 1 1 1 ...\n $ name..username      : int  0 0 0 0 0 0 0 0 0 0 ...\n $ external.URL        : int  0 0 0 0 0 1 0 0 0 1 ...\n $ private             : int  0 0 1 0 1 0 0 0 0 0 ...\n $ nums.length.username: chr  \"(0, 0.5]\" \"0\" \"(0, 0.5]\" \"0\" ...\n $ has.nums.fullname   : num  0 0 0 0 0 0 0 0 0 0 ...\n $ fullname.words      : chr  \"0\" \"[1, 2]\" \"[1, 2]\" \"[1, 2]\" ...\n $ has.description     : num  1 1 0 1 0 1 1 0 1 1 ...\n $ X.posts             : chr  \"(0, 100]\" \"&gt; 100\" \"(0, 100]\" \"&gt; 100\" ...\n $ X.followers         : chr  \"&gt; 200\" \"&gt; 200\" \"[20, 200]\" \"&gt; 200\" ...\n $ X.follows           : chr  \"&gt; 200\" \"&gt; 200\" \"[20, 200]\" \"&gt; 200\" ...\n $ fake                : int  0 0 0 0 0 0 0 0 0 0 ...\n\n\nAhora arules puede generar las reglas fácilmente a partir de este dataset usando el algoritmo apriori. Directamente se podría aplicar apriori, pero lo suyo es convertir el dataset a un objeto transaccional primero.\n\n4.2.1 Objeto transaccional\nAntes de ello, para que la conversion se haga bien, tenemos que poner nuestras variables binarias como variables de tipo factor, si no la conversión a objeto transaccional no se hará bien:\n\ndatarules$profile.pic &lt;- as.factor(datarules$profile.pic)\ndatarules$external.URL &lt;- as.factor(datarules$external.URL)\ndatarules$name..username &lt;- as.factor(datarules$name..username)\ndatarules$private &lt;- as.factor(datarules$private)\ndatarules$has.nums.fullname &lt;- as.factor(datarules$has.nums.fullname)\ndatarules$has.description &lt;- as.factor(datarules$has.description)\ndatarules$fake &lt;- as.factor(datarules$fake)\n\nAhora si, converitmos:\n\nTdatarules &lt;- as(datarules, \"transactions\")\nTdatarules@itemInfo$labels\n\n [1] \"profile.pic=0\"                 \"profile.pic=1\"                \n [3] \"name..username=0\"              \"name..username=1\"             \n [5] \"external.URL=0\"                \"external.URL=1\"               \n [7] \"private=0\"                     \"private=1\"                    \n [9] \"nums.length.username=(0, 0.5]\" \"nums.length.username=(0.5, 1]\"\n[11] \"nums.length.username=0\"        \"has.nums.fullname=0\"          \n[13] \"has.nums.fullname=1\"           \"fullname.words=[1, 2]\"        \n[15] \"fullname.words=&gt; 2\"            \"fullname.words=0\"             \n[17] \"has.description=0\"             \"has.description=1\"            \n[19] \"X.posts=(0, 100]\"              \"X.posts=&gt; 100\"                \n[21] \"X.posts=0\"                     \"X.followers=[20, 200]\"        \n[23] \"X.followers=&lt; 20\"              \"X.followers=&gt; 200\"            \n[25] \"X.follows=[20, 200]\"           \"X.follows=&lt; 20\"               \n[27] \"X.follows=&gt; 200\"               \"fake=0\"                       \n[29] \"fake=1\"                       \n\n\nComo vemos, la conversión ha hecho justamente lo que queríamos. Por ejemplo, la variable X.posts, que le dimos tres valores distintos, se han convertido en 3 variables, que cada una de ellas es binaria. Es una técnica que podríamos haber hecho a mano, pero que ya que el comando as(…, “transactions”) lo hace por nosotros, no está mal aprovecharlo. Ahora tenemos 29 variables.\n\n\n4.2.2 Apriori\n\nrules &lt;- apriori(Tdatarules, parameter = list(conf=0.1, supp=0.2, target=\"rules\"))\n\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support minlen\n        0.1    0.1    1 none FALSE            TRUE       5     0.2      1\n maxlen target  ext\n     10  rules TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 115 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[29 item(s), 576 transaction(s)] done [0.00s].\nsorting and recoding items ... [21 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 4 5 6 7 8 done [0.00s].\nwriting ... [6751 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n\nlength(rules)\n\n[1] 6751\n\n\nEl hecho de haber usado un soporte de 0.05 y 0.1 ha sido nuestra elección para filtrar entre las miles de reglas que hay si no ponemos un límite. El uso de “target = rules” no es necesario, pero es para recordar que estamos buscando reglas. También se pueden buscar otras cosas como los conjuntos de items más frequentes.\nVamos a continuar filtrando estas reglas, para quedarnos con las mejores. Primero vamos a eliminar las reglas redundantes.\n\nindices_no_redundantes &lt;- which(!is.redundant(rules))\nrules &lt;- rules[indices_no_redundantes]\ninspect(head(rules))\n\n    lhs    rhs                     support   confidence coverage lift count\n[1] {}  =&gt; {X.posts=&gt; 100}         0.2204861 0.2204861  1        1    127  \n[2] {}  =&gt; {X.posts=0}             0.2725694 0.2725694  1        1    157  \n[3] {}  =&gt; {profile.pic=0}         0.2986111 0.2986111  1        1    172  \n[4] {}  =&gt; {X.follows=[20, 200]}   0.3663194 0.3663194  1        1    211  \n[5] {}  =&gt; {private=1}             0.3819444 0.3819444  1        1    220  \n[6] {}  =&gt; {X.followers=[20, 200]} 0.3871528 0.3871528  1        1    223  \n\n\nY vamos a quedarnos solo con las significativas con el método de fisher:\n\nindices_significativos &lt;- is.significant(rules, method=\"fisher\")\nrules &lt;- rules[indices_significativos]\n\nDe esta manera nos hemos quedado con muchas menos reglas, pero con mucha mas relevancia. No sirven de nada miles de reglas si luego ni si quiera podemos trabajar con ellas.\n\n\n4.2.3 Reglas que inducen cuenta falsa\nLo que nos interesa son las reglas que nos lleven a que la cuenta es fake, vamos a observar estas:\n\nreglas_fake &lt;- subset(rules, rhs %in% \"fake=1\")\n\n\n\n[1] \"Tenemos 38 reglas que nos llevan a que la cuenta es falsa.\"\n\n\nVamos a observar las 5 mejores reglas ordenadas por lift:\n\nreglas_fake_lift &lt;- sort(reglas_fake, by=\"lift\")\ninspect(reglas_fake_lift[1:5])\n\n    lhs                                       rhs      support   confidence\n[1] {profile.pic=0, X.posts=0}             =&gt; {fake=1} 0.2152778 1.0000000 \n[2] {profile.pic=0, has.description=0}     =&gt; {fake=1} 0.2829861 1.0000000 \n[3] {profile.pic=0, private=0}             =&gt; {fake=1} 0.2100694 1.0000000 \n[4] {profile.pic=0, fullname.words=[1, 2]} =&gt; {fake=1} 0.2725694 0.9936709 \n[5] {profile.pic=0}                        =&gt; {fake=1} 0.2951389 0.9883721 \n    coverage  lift     count\n[1] 0.2152778 2.000000 124  \n[2] 0.2829861 2.000000 163  \n[3] 0.2100694 2.000000 121  \n[4] 0.2743056 1.987342 157  \n[5] 0.2986111 1.976744 170  \n\n\nPor primera vez en lo que llevamos de libro hemos obtenido un conocimiento interesante para la detección de cuentas falsas de Instagram.\nLa primera regla, por ejemplo, nos está diciendo que con una confianza del 100% en nuestro dataset, las cuentas que no tienen foto de perfil ni posts, son falsas.\nLo mismo con las siguientes reglas que tienen 100% de confianza: - Las cuentas sin foto de perfil ni descripción, son falsas - Las cuentas sin foto de perfil y que son públicas son falsas\nObviamente esto no significan que cualquier cuenta de Instagram que encontremos en Internet es falsa si cumple dichas condiciones, si no que en nuestro dataset siempre es así, y nuestro dataset no es demasiado grande. Necesitaríamos un dataset mucho más grande para poder afirmar esto para un caso general, pero ya son conclusiones interesantes.\nTambién vemos que la quinta regla nos dice que casi siempre que una cuenta no tiene foto de perfil, es falsa. Por ello no podemos hacer caso a lo que dicen las reglas sin más, tenemos que ver más opciones y usar más técnicas de análisis de datos, pero como primeros conocimientos, es un buen resultado.\nOtra cosa a tener en cuenta es el soporte de las reglas. Vamos a ver que dicen las reglas con más soporte:\nMejores reglas ordenadas por soporte:\n\nreglas_fake_support &lt;- sort(reglas_fake, by=\"support\")\ninspect(reglas_fake_support[1:5])\n\n    lhs                                        rhs      support   confidence\n[1] {external.URL=0}                        =&gt; {fake=1} 0.5000000 0.5658153 \n[2] {fullname.words=[1, 2]}                 =&gt; {fake=1} 0.4322917 0.5297872 \n[3] {external.URL=0, fullname.words=[1, 2]} =&gt; {fake=1} 0.4322917 0.5942721 \n[4] {has.description=0}                     =&gt; {fake=1} 0.4305556 0.7607362 \n[5] {external.URL=0, has.description=0}     =&gt; {fake=1} 0.4305556 0.7774295 \n    coverage  lift     count\n[1] 0.8836806 1.131631 288  \n[2] 0.8159722 1.059574 249  \n[3] 0.7274306 1.188544 249  \n[4] 0.5659722 1.521472 248  \n[5] 0.5538194 1.554859 248  \n\n\nMás soporte significa que esos patrones se dan mas veces en el dataset, pero sin tener en cuenta la confianza de estas reglas, no sirve de nada. Por ejemplo, la primera regla nos dice que si una cuenta no tiene enlace externo, entonces es falsa, y se da el 50% de las veces en nuestro dataset. Pero la confianza es solo del 56%. No es bueno fiarse simplemente de esta regla.\nEn vez de buscar reglas tan simples y generales como “dada una sola cosa entonces la cuenta es fake” podemos buscar reglas que tengan a la izquierda varios items, lo que hará que el soporte sea más bajo, pero puede que nos de reglas mas fiables.\nQue una cuenta sea fake no va a depender únicamente de que no tenga foto de perfil o de que no tenga descripción, si no que probablemente cada condición tenga cierto peso y no sea tan sencillo.\nPor todo esto no podemos fiarnos solamente del soporte de la regla, y tenemos que mirar también la confianza. O mejor aún, el lift.\n\n\n4.2.4 Reglas que inducen cuenta real\nAntes de buscar reglas con más items en la parte izquierda, vamos a ver las reglas que nos llevan a que la cuenta no es falsa.\n\nreglas_reales &lt;- subset(rules, rhs %in% \"fake=0\")\n\n\n\n[1] \"Tenemos 138 reglas que nos llevan a que la cuenta es real.\"\n\n\nVamos a ver las reglas con mayor lift:\n\nreglas_reales_lift &lt;- sort(reglas_reales, by=\"lift\")\ninspect(reglas_reales_lift[1:5])\n\n    lhs                          rhs        support confidence  coverage     lift count\n[1] {nums.length.username=0,                                                           \n     fullname.words=[1, 2],                                                            \n     has.description=1,                                                                \n     X.followers=&gt; 200}       =&gt; {fake=0} 0.2013889  0.9830508 0.2048611 1.966102   116\n[2] {profile.pic=1,                                                                    \n     name..username=0,                                                                 \n     nums.length.username=0,                                                           \n     fullname.words=[1, 2],                                                            \n     has.description=1}       =&gt; {fake=0} 0.2378472  0.9785714 0.2430556 1.957143   137\n[3] {profile.pic=1,                                                                    \n     nums.length.username=0,                                                           \n     fullname.words=[1, 2],                                                            \n     X.followers=&gt; 200,                                                                \n     X.follows=&gt; 200}         =&gt; {fake=0} 0.2222222  0.9770992 0.2274306 1.954198   128\n[4] {X.posts=&gt; 100,                                                                    \n     X.followers=&gt; 200}       =&gt; {fake=0} 0.2013889  0.9747899 0.2065972 1.949580   116\n[5] {profile.pic=1,                                                                    \n     nums.length.username=0,                                                           \n     has.description=1,                                                                \n     X.followers=&gt; 200}       =&gt; {fake=0} 0.2552083  0.9735099 0.2621528 1.947020   147\n\n\nSon bastantes interesantes y precisamente tienen el componente que comentabamos antes. No son reglas tan generales como “si tiene foto de perfil la cuenta es real”, si no que tiene en cuenta mucho mos detalles, como or ejemplo la segunda regla. Con un 97.85% de confianza, si la cuenta tiene foto de perfil, el nombre real y el de usuario son distintos, tiene entre 1 y 2 palabras en el nombre real y tiene descripción, entonces, es real.\nEstas reglas son muy interesantes y nos dan pistas y conocimiento sobre que elementos son claves a la hora de ver si una cuenta es falsa o no.\n\n\n4.2.5 Reglas con más de 6 items\nVamos ahora a buscar reglas que tengan al menos 6 items en total, (con la idea de que tengan 5 en la parte izquierda y 1 en la derecha), para ver que tipo de reglas podemos conseguir.\n\nbig_rules &lt;- apriori(Tdatarules, parameter = \n                       list(conf=0.1, supp=0.2, minlen=6, target=\"rules\"))\n\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support minlen\n        0.1    0.1    1 none FALSE            TRUE       5     0.2      6\n maxlen target  ext\n     10  rules TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 115 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[29 item(s), 576 transaction(s)] done [0.00s].\nsorting and recoding items ... [21 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 4 5 6 7 8 done [0.00s].\nwriting ... [1351 rule(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n\n\nEliminamos las reglas redundantes\n\nindices_no_redundantes &lt;- which(!is.redundant(big_rules))\nbig_rules &lt;- big_rules[indices_no_redundantes]\n\nY nos quedamos con las significativas\n\nindices_significativos &lt;- is.significant(big_rules, method=\"fisher\")\nbig_rules &lt;- big_rules[indices_significativos]\n\nVeamos las reglas que nos llevan a que la cuenta es falsa:\n\nbig_reglas_fake &lt;- subset(big_rules, rhs %in% \"fake=1\")\n\n\n\n[1] \"Tenemos 17 reglas con 6 o más items que nos llevan a que la cuenta es falsa.\"\n\n\nLas 5 más importantes ordenadas por lift:\n\nbig_reglas_fake_lift &lt;- sort(big_reglas_fake, by=\"lift\")\ninspect(big_reglas_fake_lift[1:3])\n\n    lhs                         rhs        support confidence  coverage lift count\n[1] {profile.pic=0,                                                               \n     external.URL=0,                                                              \n     has.nums.fullname=0,                                                         \n     fullname.words=[1, 2],                                                       \n     has.description=0}      =&gt; {fake=1} 0.2187500          1 0.2187500    2   126\n[2] {profile.pic=0,                                                               \n     name..username=0,                                                            \n     external.URL=0,                                                              \n     fullname.words=[1, 2],                                                       \n     has.description=0}      =&gt; {fake=1} 0.2430556          1 0.2430556    2   140\n[3] {profile.pic=0,                                                               \n     name..username=0,                                                            \n     has.nums.fullname=0,                                                         \n     fullname.words=[1, 2],                                                       \n     has.description=0}      =&gt; {fake=1} 0.2152778          1 0.2152778    2   124\n\n\nEstamos viendo patrones que creíamos que no se daban en las cuentas falsas, como por ejemplo, que cuentas con 1 o 2 palabras en el nombre completo también pueden llevar a una cuenta falsa, y sin números en el nombre completo, con el nombre completo distinto del nombre de usuario…\nEsto nos indica que detectar una cuenta falsa no es tan fácil como buscar lo que pensamos que no es normal, si no que es más complejo.\n\n\n4.2.6 Reglas entre otros atributos\nAhora vamos a buscar reglas entre los distintos atributos del dataset, que no tengan nada que ver con la clasificación de si la cuenta es falsa o no, con la idea de encontrar reglas que nos permitan derivar unos atributos a partir de otros. Usaremos las reglas generadas y almacenadas en la variable rules.\nVamos a filtrar de forma que la regla no contenga nada referente a la variable fake, ni a la izquierda ni a la derecha. Vamos a filtrar también por reglas que tengan al menos 0.8 de confianza:\n\nrules_sin_fake &lt;- subset(rules, \n                              !(rhs %pin% \"fake=\") & \n                              !(lhs %pin% \"fake=\") &\n                              confidence &gt; 0.8)\npaste(\"Tenemos\", length(rules_sin_fake), \"reglas con confidence &gt; 0.8 \n      y sin la variable fake\")\n\n[1] \"Tenemos 255 reglas con confidence &gt; 0.8 \\n      y sin la variable fake\"\n\n\nOrdenamos por lift:\n\nrules_sin_fake_confidence &lt;- sort(rules_sin_fake, by=\"lift\")\ninspect(rules_sin_fake_confidence[1:4])\n\n    lhs                          rhs                   support confidence  coverage     lift count\n[1] {has.description=0,                                                                           \n     X.posts=0}               =&gt; {profile.pic=0}     0.2135417  0.8255034 0.2586806 2.764476   123\n[2] {profile.pic=1,                                                                               \n     X.posts=&gt; 100}           =&gt; {X.followers=&gt; 200} 0.2048611  0.9440000 0.2170139 2.107535   118\n[3] {X.posts=&gt; 100}           =&gt; {X.followers=&gt; 200} 0.2065972  0.9370079 0.2204861 2.091925   119\n[4] {profile.pic=1,                                                                               \n     nums.length.username=0,                                                                      \n     fullname.words=[1, 2],                                                                       \n     X.follows=&gt; 200}         =&gt; {X.followers=&gt; 200} 0.2274306  0.9357143 0.2430556 2.089037   131\n\n\nVemos relaciones interesantes:\n\nCuentas sin descripción ni publicaciones, no tienen foto de perfil\nCuentas con más de 100 publicaciones, tienen más de 200 seguidores\nCuentas con foto de perfil, sin numeros en el nombre de usuario, con un nombre real con 1 o 2 palabras y más de 200 personas seguidas, tienen más de 200 seguidores\n\nEstamos viendo que nuestros datos tienen relaciones entre sí, algunas más o menos lógicas, y que hay ciertas cosas que nos dan pistas sobre si una cuenta es falsa o no.\n\n\n4.2.7 Conjuntos de items frecuentes\nPor último, vamos a buscar los conjuntos de items más frecuentes en nuestro dataset. Apriori, además de conseguirnos reglas, también nos permite conseguir los frequent itemsets\n\nitems &lt;- apriori(Tdatarules, parameter = list(\n  supp = 0.2, \n  conf = 0.3, \n  target=\"frequent itemsets\"))\n\nApriori\n\nParameter specification:\n confidence minval smax arem  aval originalSupport maxtime support minlen\n         NA    0.1    1 none FALSE            TRUE       5     0.2      1\n maxlen            target  ext\n     10 frequent itemsets TRUE\n\nAlgorithmic control:\n filter tree heap memopt load sort verbose\n    0.1 TRUE TRUE  FALSE TRUE    2    TRUE\n\nAbsolute minimum support count: 115 \n\nset item appearances ...[0 item(s)] done [0.00s].\nset transactions ...[29 item(s), 576 transaction(s)] done [0.00s].\nsorting and recoding items ... [21 item(s)] done [0.00s].\ncreating transaction tree ... done [0.00s].\nchecking subsets of size 1 2 3 4 5 6 7 8 done [0.00s].\nsorting transactions ... done [0.00s].\nwriting ... [1648 set(s)] done [0.00s].\ncreating S4 object  ... done [0.00s].\n\n\nVamos a ver los más frecuentes (ordenados por soporte)\n\nfrequent_items &lt;- sort(items, by=\"support\")\ninspect(head(frequent_items))\n\n    items                                   support   count\n[1] {name..username=0}                      0.9652778 556  \n[2] {has.nums.fullname=0}                   0.8993056 518  \n[3] {name..username=0, has.nums.fullname=0} 0.8888889 512  \n[4] {external.URL=0}                        0.8836806 509  \n[5] {name..username=0, external.URL=0}      0.8506944 490  \n[6] {fullname.words=[1, 2]}                 0.8159722 470  \n\n\nObservamos que lo más común en nuestro dataset es no tener el nombre de usuario igual al nombre real, con un 96.52% de veces, no tener números en el nombre real, no tener enlace externo…\nVamos a visualizarlo mediante el objeto transaccional. Veamos los 10 items más frecuentes:\n\nitemFrequencyPlot(Tdatarules, topN = 10)"
  },
  {
    "objectID": "association_rules.html#visualización-con-arulesviz",
    "href": "association_rules.html#visualización-con-arulesviz",
    "title": "4  Reglas de asociación",
    "section": "4.3 Visualización con arulesViz",
    "text": "4.3 Visualización con arulesViz\narulesViz es una herramienta para visualizar y comprender las reglas de asociación generadas con arules en R. Permite representar gráficamente las relaciones entre elementos en nuestros datos, facilitando la identificación de patrones complejos.\nCon arulesViz, podemos visualizar las reglas como grafos o diagramas de coordenadas paralelas, lo que nos ayuda a entender la importancia relativa de cada elemento.\nRequieren un mínimo de entendimiento ya que no son gráficos tan intuitivos como uno de barras, pero al entenderlos correctamente, proporcionan mucha información muy útil de manera visual.\n\nlibrary(arulesViz)\n\n\nplot(rules, method = \"graph\", control = list(type = \"items\"),\n     shading = \"lift\", measure = \"confidence\")\n\nAvailable control parameters (with default values):\nlayout   =  stress\ncircular     =  FALSE\nggraphdots   =  NULL\nedges    =  &lt;environment&gt;\nnodes    =  &lt;environment&gt;\nnodetext     =  &lt;environment&gt;\ncolors   =  c(\"#EE0000FF\", \"#EEEEEEFF\")\nengine   =  ggplot2\nmax  =  100\nverbose  =  FALSE\n\n\n\n\n\nEste gráfico nos muestra cómo ciertos atributos están relacionados entre sí con base en el lift y la confianza. Por ejemplo, se puede observar que “fake=1” tiene una relación significativa con otros atributos como “X.posts=0” y “profile.pic=0”, lo que sugiere que estas combinaciones son más comunes de lo esperado y tienen alta confianza en la regla.\n\nplot(reglas_fake, method = \"graph\")\n\n\n\n\n“profile.pic=0” tiene un alto lift y soporte, lo que indica que es común encontrar cuentas sin foto de perfil en el conjunto de datos y que esta característica tiene una alta co-ocurrencia significativa con otros atributos. Las reglas asociadas a “fake=1” también tienen un alto soporte, sugiriendo que estas combinaciones son comunes en los datos.\n\nplot(reglas_fake, method = \"paracoord\", control = list(reorder = TRUE))\n\n\n\n\nPodemos ver que las reglas que tienen “X.posts=0” y “fake=1” también suelen tener valores específicos para otras variables como “X.followers” y “profile.pic”. Este gráfico facilita la identificación de patrones complejos y de cómo múltiples atributos se combinan en las reglas de asociación."
  },
  {
    "objectID": "association_rules.html#conclusiones",
    "href": "association_rules.html#conclusiones",
    "title": "4  Reglas de asociación",
    "section": "4.4 Conclusiones",
    "text": "4.4 Conclusiones\nCon las de reglas de asociación, hemos descubierto que nuestros datos contienen un conocimiento valioso y hemos identificado las primeras relaciones significativas entre las características de las cuentas de Instagram. Este análisis nos ha permitido derivar varias reglas que aportan información relevante sobre el comportamiento de estas cuentas y su clasificación como falsas o reales:\n\nCuentas falsas (dentro de nuestro dataset):\n\nCon una confianza del 100% en nuestro dataset, las cuentas que no tienen foto de perfil ni publicaciones son falsas.\nLas cuentas sin foto de perfil y sin descripción también son falsas.\nLas cuentas sin foto de perfil y que son públicas son falsas.\n\nCuentas reales (dentro de nuestro dataset):\n\nCon un 97.85% de confianza en nuestro dataset, las cuentas con foto de perfil, nombre de usuario distinto del nombre real, entre 1 y 2 palabras en el nombre real, y que tienen descripción, son reales.\nLas cuentas con foto de perfil, sin números en el nombre completo, nombre completo diferente del nombre de usuario, y con entre 1 y 2 palabras en el nombre real, son reales con una alta confianza en nuestro dataset.\n\nReglas de asociación generales:\n\nLas cuentas sin descripción ni publicaciones, no tienen foto de perfil.\nLas cuentas con más de 100 publicaciones, tienen más de 200 seguidores.\nLas cuentas con foto de perfil, sin números en el nombre de usuario, con un nombre real de 1 o 2 palabras, y que siguen a más de 200 cuentas, tienen más de 200 seguidores.\n\nItemsets más frecuentes:\n\nTener el nombre de usuario distinto del nombre real\nNo tener números en el nombre real\nNo tener enlace en el perfil\n\n\nEstas reglas nos muestran patrones interesantes y nos ayudan a entender mejor cómo ciertos atributos de las cuentas de Instagram se relacionan entre sí y con la autenticidad de la cuenta.\nSin embargo, es crucial tener en cuenta que estas conclusiones se basan en un conjunto de datos limitado. Para poder generalizar estos hallazgos a una población más amplia de cuentas de Instagram, necesitaríamos un dataset más grande y representativo.\nAdemás, aunque las reglas de asociación nos han proporcionado una buena base de conocimiento, debemos seguir aplicando otras técnicas de análisis de datos para extraer aún más información y verificar la robustez de nuestros hallazgos. Métodos adicionales como la regresión y FCA pueden complementar y profundizar en el conocimiento obtenido hasta ahora, mejorando así nuestra capacidad de detectar cuentas falsas y entender el comportamiento de las cuentas de Instagram en general."
  },
  {
    "objectID": "formal_concept_analysis.html#pre-processing",
    "href": "formal_concept_analysis.html#pre-processing",
    "title": "5  FCA",
    "section": "5.1 Pre-processing",
    "text": "5.1 Pre-processing\nAl igual que para las reglas de asociación, necesitamos hacer un pre-procesado de los datos, ya que para aplicar FCA necesitamos que nuestras variabes sean binarias.\nAlgunas de ellas ya lo son, pero las que no lo son, tendremos que hacerles el proceso de escalado (scaling).\nVamos a empezar convirtiendo las variables description.length y nums.length.fullname como antes a has.description y has.nums.fullname, ya que creemos que es la información importante que contienen estas variables.\n\ndataset &lt;- dataset %&gt;%\n  mutate(has.description=as.numeric(description.length &gt; 0)) %&gt;%\n  mutate(has.nums.fullname=as.numeric(nums.length.fullname &gt; 0))\n\ndataset$description.length &lt;- NULL\ndataset$nums.length.fullname &lt;- NULL\n\nAhora, para todas las varaibles binarias, vamos a crear su simétrica. Es decir, si tenemos la variable fake que representa que una cuenta es falsa, creamos la varaible no.fake, que representa que una cuenta no es falsa.\n¿Por qué simplemente no tener una variable y el valor 1 significa la afirmación de la condición y valor 0 la negación?\nCuando hicimos el objeto transaccional para aplicar el algoritmo apriori del paquete arules, se nos crearon a partir de cada varaible binaria, dos variables. Por ejemplo, para fake, se nos creó fake=1 y fake=0. Es el mismo caso que tenemos ahora, solo que en aquel caso se hizo automáticamente, y ahora tenemos que hacerlo nosotros mismos.\n\ndataset &lt;- dataset %&gt;%\n  mutate(no.fake = as.numeric(!fake)) %&gt;%\n  mutate(no.profile.pic = as.numeric(!profile.pic)) %&gt;%\n  mutate(no.name..username = as.numeric(!name..username)) %&gt;%\n  mutate(no.external.URL = as.numeric(!external.URL)) %&gt;%\n  mutate(no.private = as.numeric(!private)) %&gt;%\n  mutate(no.has.description = as.numeric(!has.description)) %&gt;%\n  mutate(no.has.nums.fullname = as.numeric(!has.nums.fullname))\n\nEsto se hace para que en nuestros conceptos, podamos tener ambos casos, la afirmación y la negación. Con el caso de fake, si solo dejásemos la variable, tendríamos conceptos en los que tenemos que se cumple “fake”, pero el no cumplimiento de fake no se representaría y no podríamos formar conceptos con cuentas que no son falsas.\nPara las 5 variables no binarias que tenemos, las vamos a escalar a variables nominales.\n¿Por qué?\nDebido a que vamos a pasarlas a intervalos, y dado el valor de una variable, esta solo estará en uno de los intervalos, y justamente esto lo conseguidmos con las variables nominales.\nPara ello, antes tenemos que crear los intervalos. Vamos a usar los mismos que usamos para aplicar las reglas de asociación:\n\nnums.length.username\n\n“0”\n“(0, 0.5]”\n“(0.5, 1]”\n\n\n\ndataset &lt;- dataset %&gt;%\n  mutate(nums.length.username=\n            ifelse(nums.length.username == 0, \n                   \"0\", ifelse(nums.length.username &lt;= 0.5, \n                               \"(0, 0.5]\", \"(0.5,1]\")))\n\n\nfullname.words\n\n“0”\n“[1, 2]”\n“&gt; 2”\n\n\n\ndataset &lt;- dataset %&gt;%\n  mutate(fullname.words =\n            ifelse(fullname.words == 0, \n                   \"0\", ifelse(fullname.words &lt;= 2, \n                               \"[1, 2]\", \"&gt; 2\")))\n\n\nX.posts\n\n“0”\n“(0, 100]”\n“&gt; 100”\n\n\n\ndataset &lt;- dataset %&gt;%\n  mutate(X.posts =\n            ifelse(X.posts == 0, \n                   \"0\", ifelse(X.posts &lt;= 100, \n                               \"(0, 100]\", \"&gt; 100\")))\n\n\nX.followers\n\n“&lt; 20”\n“[20, 200]”\n“&gt; 200”\n\n\n\ndataset &lt;- dataset %&gt;% \n  mutate(X.followers =\n            ifelse(X.followers &lt; 20, \n                   \"&lt; 20\", ifelse(X.followers &lt;= 200, \n                               \"[20, 200]\", \"&gt; 200\")))\n\n\nX.follows\n\n“&lt; 20”\n“[20, 200]”\n“&gt; 200”\n\n\n\ndataset &lt;- dataset %&gt;%\n  mutate(X.follows =\n            ifelse(X.follows &lt; 20, \n                   \"&lt; 20\", ifelse(X.follows &lt;= 200, \n                               \"[20, 200]\", \"&gt; 200\")))\n\nVamos ahora a crear nuestro objeto FormalContext del paquete fcaR:\n\nfc &lt;- FormalContext$new(dataset)\n\nHemos tenido que crear el objeto antes de terminar el pre-processing, ya que para las variables no binarias, es el objeto FormalContext el que nos proporciona los mecanismos de escalado.\nVamosa escalar las 5 variales no binarias que hemos convertido a intervalos, mediante la función scale del objeto FormalContext:\n\nfc$scale(type = \"nominal\", \"nums.length.username\")\nfc$scale(type = \"nominal\", \"X.posts\")\nfc$scale(type = \"nominal\", \"X.followers\")\nfc$scale(type = \"nominal\", \"X.follows\")\nfc$scale(type = \"nominal\", \"fullname.words\")\n\nHemos pasado de tener 12 variables, a tener:\n\nfc$attributes\n\n [1] \"profile.pic\"                     \"nums.length.username = (0, 0.5]\"\n [3] \"nums.length.username = (0.5,1]\"  \"nums.length.username = 0\"       \n [5] \"fullname.words = [1, 2]\"         \"fullname.words = &gt; 2\"           \n [7] \"fullname.words = 0\"              \"name..username\"                 \n [9] \"external.URL\"                    \"private\"                        \n[11] \"X.posts = (0, 100]\"              \"X.posts = &gt; 100\"                \n[13] \"X.posts = 0\"                     \"X.followers = [20, 200]\"        \n[15] \"X.followers = &lt; 20\"              \"X.followers = &gt; 200\"            \n[17] \"X.follows = [20, 200]\"           \"X.follows = &lt; 20\"               \n[19] \"X.follows = &gt; 200\"               \"fake\"                           \n[21] \"has.description\"                 \"has.nums.fullname\"              \n[23] \"no.fake\"                         \"no.profile.pic\"                 \n[25] \"no.name..username\"               \"no.external.URL\"                \n[27] \"no.private\"                      \"no.has.description\"             \n[29] \"no.has.nums.fullname\"           \n\n\nCon estos atributos estamos preparados para empezar a crear conceptos y estudiarlos para extraer conocimiento de los datos."
  },
  {
    "objectID": "formal_concept_analysis.html#primeros-pasos",
    "href": "formal_concept_analysis.html#primeros-pasos",
    "title": "5  FCA",
    "section": "5.2 Primeros pasos",
    "text": "5.2 Primeros pasos\nVamos a observar como hemos transformado las variables que tenían muchos valores, tomando de ejemplo, X.follows:\n\nplot(fc[40:60][,c(17, 18, 19)])\n\n\n\n\nHemos tomado las observaciones de la 40 a la 60 y las columnas que corresponden con X.follows. Como se puede apreciar, la clasificación es exclusiva, si una persona sigue a a más de 200 personas, entonces no está en “[20, 200]” ni en “&lt; 200”, que es justo lo que pensamos que nos dará los mejores conceptos.\nVeamos el contexto formal completo:\n\nplot(fc)\n\n\n\n\nEsto básicamente representa toda la información que tenemos, pero obviamente de esta forma no podemos deducir nada.\nComo hemos visto los atributos son todas nuestras variables\n\nattr_ig &lt;- fc$attributes\nattr_ig\n\n [1] \"profile.pic\"                     \"nums.length.username = (0, 0.5]\"\n [3] \"nums.length.username = (0.5,1]\"  \"nums.length.username = 0\"       \n [5] \"fullname.words = [1, 2]\"         \"fullname.words = &gt; 2\"           \n [7] \"fullname.words = 0\"              \"name..username\"                 \n [9] \"external.URL\"                    \"private\"                        \n[11] \"X.posts = (0, 100]\"              \"X.posts = &gt; 100\"                \n[13] \"X.posts = 0\"                     \"X.followers = [20, 200]\"        \n[15] \"X.followers = &lt; 20\"              \"X.followers = &gt; 200\"            \n[17] \"X.follows = [20, 200]\"           \"X.follows = &lt; 20\"               \n[19] \"X.follows = &gt; 200\"               \"fake\"                           \n[21] \"has.description\"                 \"has.nums.fullname\"              \n[23] \"no.fake\"                         \"no.profile.pic\"                 \n[25] \"no.name..username\"               \"no.external.URL\"                \n[27] \"no.private\"                      \"no.has.description\"             \n[29] \"no.has.nums.fullname\"           \n\n\nLos objetos son simplemente las observaciones, las filas de nuestro dataset, cada cuenta de Instagram que tenemos.\n\nobj_ig &lt;- fc$objects\nstr(obj_ig)\n\n chr [1:576] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\" \"9\" \"10\" \"11\" \"12\" \"13\" \"14\" ...\n\n\nVamos a calcular manualmente el cierre de algunos atributos, para sacar las primeras conclusiones:\n\nCierre de fake\n\n\nS &lt;- Set$new(attr_ig)\nS$assign(fake = 1)\nfc$intent(fc$extent(S))\n\n{fake, no.external.URL}\n\n\n¿Qué significa esto?\nTodas las cuentas que son falsas, no tienen un enlace externo en el perfil. Lo que hemos hecho es calcular el cierre de “fake”, que es “fake, no.external.URL”.\nVamos a hacer ahora el cierre de external.URL.\n\nCierre de no.external.URL\n\n\nS &lt;- Set$new(attr_ig)\nS$assign(external.URL = 1)\nfc$intent(fc$extent(S))\n\n{profile.pic, external.URL, no.fake}\n\n\nTodas las cuentas que tienen un enlace externo, también tienen foto de perfil, y son reales. Vemos viendo el potencial que tiene el cierre, extra un conocimiento valioso."
  },
  {
    "objectID": "formal_concept_analysis.html#generando-conceptos",
    "href": "formal_concept_analysis.html#generando-conceptos",
    "title": "5  FCA",
    "section": "5.3 Generando conceptos",
    "text": "5.3 Generando conceptos\nVamos a generar todos los conceptos:\n\nfc$find_concepts()\n\nNos han salido:\n\nfc$concepts$size()\n\n[1] 20421\n\n\nTenemos muchos conceptos. Vamos a visualizar el primero:\n\nfc$concepts[1]\n\nA set of 1 concepts:\n1: ({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576}, {})\n\n\n¿Qué son todos estos números?\nCada número representa una cuenta de Instagram, una observación, una fila de nuestro dataset. Si nos fijamos bien, en esta lista, apareecen todos los números del 1 al 576, y es que justamente tenemos 576 observaciones en nuestro dataset. La otra parte del concepto, es {}. Esto quiere decir que todos los objetos (todas las cuentas) tienen los atributos {} (trivial). No es un concepto útil, vamos a visualizar el que se encuentra en el punto medio:\n\nn &lt;- fc$concepts$size()\nindice &lt;- floor(n/2)\nconcepto_medio &lt;- fc$concepts[indice]\nconcepto_medio\n\nA set of 1 concepts:\n1: ({3, 75, 82, 113, 114, 121, 129, 152, 191, 196, 250, 254, 266, 291, 295, 297, 305, 333, 343, 351, 352, 358, 359, 360, 363, 364, 370, 380, 382, 387, 389, 393, 394, 427, 433, 440, 441, 459, 462}, {nums.length.username = (0, 0.5], fullname.words = [1, 2], private, X.posts = (0, 100], no.external.URL})\n\n\nEste concepto es más interesante, tenemos ciertas cuentas de Instagram que cumplen una serie de atributos.\n\nn_cuentas &lt;- sum(concepto_medio$extents())\nattr_medio &lt;- attr_ig[as.logical(concepto_medio$intents())]\n\npaste0(\"Tenemos que \", n_cuentas, \" tienen los atributos:\")\n\n[1] \"Tenemos que 39 tienen los atributos:\"\n\nattr_medio\n\n[1] \"nums.length.username = (0, 0.5]\" \"fullname.words = [1, 2]\"        \n[3] \"private\"                         \"X.posts = (0, 100]\"             \n[5] \"no.external.URL\"                \n\n\nCon fcaR tenemos una forma sencilla y eficiente de obtener conceptos, con los que podemos ver agrupaciones de nuestros datos, donde en nuestro caso encontramos el número de cuentas que comparten una serie de atributos.\nAhora vamos a visualizar nuestros conceptos en forma de retículo, pero para ello, vamos a crear antes un subreticulo, pues tenemos demasiados conceptos.\nVamos a crear el subreticulo de los conceptos con soporte mayor al 0.89, para asi quedarnos con pocos conceptos y poder visualizarlos:\n\nidx &lt;- which(fc$concepts$support() &gt; 0.8)\nsublaticce &lt;- fc$concepts$sublattice(idx)\n\n\nsublaticce$plot()\n\n\n\n\nDado que lo que teníamos antes es un retículo, podemos calcular el ínfimo y el supremo de nuestro subreticulo:\n\nfc$concepts$infimum(sublaticce)\n\n({2, 3, 4, 5, 7, 8, 11, 21, 23, 24, 30, 31, 33, 34, 36, 38, 39, 40, 43, 47, 48,\n  49, 52, 57, 58, 59, 60, 61, 63, 67, 68, 71, 72, 73, 74, 75, 76, 77, 78, 80,\n  81, 82, 84, 87, 90, 91, 92, 93, 94, 95, 96, 97, 101, 104, 109, 110, 111, 112,\n  113, 114, 115, 117, 121, 123, 124, 125, 127, 128, 129, 132, 133, 135, 139,\n  142, 144, 145, 146, 149, 151, 152, 153, 154, 155, 156, 158, 159, 161, 163,\n  164, 167, 169, 170, 171, 176, 178, 180, 181, 182, 186, 188, 189, 191, 192,\n  193, 196, 197, 198, 201, 203, 204, 207, 211, 212, 214, 216, 218, 221, 222,\n  223, 224, 225, 226, 227, 229, 230, 231, 232, 236, 237, 239, 240, 241, 242,\n  244, 245, 249, 250, 252, 253, 255, 256, 258, 260, 262, 264, 265, 266, 267,\n  268, 269, 270, 272, 273, 274, 275, 277, 278, 280, 281, 282, 284, 285, 286,\n  287, 288, 289, 290, 291, 294, 296, 297, 298, 299, 300, 301, 303, 304, 305,\n  306, 307, 308, 310, 311, 312, 314, 315, 316, 318, 319, 320, 321, 322, 323,\n  325, 327, 328, 329, 331, 333, 337, 338, 340, 341, 342, 343, 344, 345, 346,\n  350, 352, 353, 356, 359, 361, 362, 364, 366, 370, 371, 372, 373, 375, 376,\n  377, 379, 380, 381, 383, 384, 386, 387, 388, 391, 392, 393, 394, 395, 397,\n  398, 400, 402, 403, 404, 406, 408, 409, 410, 411, 412, 414, 416, 417, 418,\n  419, 420, 421, 423, 424, 426, 427, 428, 430, 431, 432, 433, 435, 437, 438,\n  439, 441, 444, 447, 449, 450, 454, 456, 457, 459, 460, 461, 463, 464, 466,\n  467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 478, 479, 480, 482, 483,\n  484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 500,\n  501, 502, 503, 504, 505, 506, 507, 508, 509, 511, 512, 514, 519, 521, 522,\n  523, 525, 526, 527, 529, 530, 531, 532, 534, 536, 538, 539, 540, 542, 543,\n  544, 545, 546, 547, 550, 553, 554, 559, 563, 564, 567, 568, 569, 571, 574,\n  575, 576}, {fullname.words = [1, 2], no.name..username, no.external.URL,\n  no.has.nums.fullname})\n\nfc$concepts$supremum(sublaticce)\n\n({1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n  23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41,\n  42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n  61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,\n  80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,\n  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n  115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n  130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n  145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n  160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174,\n  175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,\n  190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204,\n  205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219,\n  220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n  235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n  250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n  265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n  280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294,\n  295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,\n  310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n  325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n  340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n  355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369,\n  370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384,\n  385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399,\n  400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414,\n  415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n  430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444,\n  445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n  460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474,\n  475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n  490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504,\n  505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n  520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534,\n  535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549,\n  550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564,\n  565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576}, {})\n\n\nEl ínfimo representa"
  },
  {
    "objectID": "formal_concept_analysis.html#generando-implicaciones",
    "href": "formal_concept_analysis.html#generando-implicaciones",
    "title": "5  FCA",
    "section": "5.4 Generando implicaciones",
    "text": "5.4 Generando implicaciones\nCon fcaR también podemos generar implicacioens a partir de nuestros conceptos. Son reglas de asociación, pero a diferencia de arules, aquí si se generan reglas con múltiples atributos en el lado derecho.\nPodemos generar reglas con el comando find_implications():\n\nfc$find_implications()\n\nHemos generado:\n\nfc$implications$cardinality()\n\n[1] 1383\n\n\nVamos a ver cual es el tamaño medio la parte izquierda y derecha de nuestras reglas:\n\nl &lt;- fc$implications$size()\ncolMeans(l)\n\n     LHS      RHS \n6.704266 1.974693 \n\n\nLa media de la parte izquierda tiene 6.7 items. En el apartado de reglas de asociación soliamos ver reglas de entre 1, 2 o 3 items como mucho a la izquierda (salvo cuando buscamos con una longitud mínima).\n\nsum(colMeans(l))\n\n[1] 8.678959\n\n\nEn promedio el número de items de nuestras reglas son 8.67.\nCon fcaR podemos aplicar una serie de simplificaciones, para eliminar reglas redundantes. Estas son; - composition - generalization - simplification - rsimplification\nVamos a aplicarlas a ver si nos eliminamos reglas redundantes\n\nfc$implications$apply_rules(rules = c(\"composition\",\n                                      \"generalization\",\n                                      \"simplification\",\n                                      \"rsimplification\"))\n\nProcessing batch\n\n\n--&gt; Composition: from 1383 to 1383.\n\n\n--&gt; Generalization: from 1383 to 1383.\n\n\n--&gt; Simplification: from 1383 to 1383.\n\n\n--&gt; Right Simplification: from 1383 to 1383.\n\n\nComo podemos leer en la salida del comando, no hemos simplificado nada, lo que significa que no teníamos reglas redundantes ni que se pudiesen simplificar.\nVamos a visualizar las mejores reglas ordenadas por soporte:\n\nindices &lt;- order(fc$implications$support(), decreasing = TRUE)\nimplicaciones_ordenadas &lt;- fc$implications[indices]\nhead(implicaciones_ordenadas)\n\nImplication set with 6 implications.\nRule 1: {fake} -&gt; {no.external.URL}\nRule 2: {profile.pic, X.followers = &gt; 200} -&gt; {no.name..username}\nRule 3: {profile.pic, X.follows = &gt; 200, no.has.nums.fullname} -&gt;\n  {no.name..username}\nRule 4: {X.followers = &gt; 200, no.fake} -&gt; {no.name..username}\nRule 5: {no.fake, no.external.URL} -&gt; {no.name..username}\nRule 6: {X.follows = &gt; 200, no.fake} -&gt; {no.name..username}\n\n\nVemos algunas conclusiones como las que sacamos con arules: - Si es falsa no tiene enlace externo - Si tiene foto de perfil y más de 2 seguidores no tiene el nombre completo igual al nombre de usuario…\nVamos a ver las reglas que nos llevan a que la cuenta es falsa:\n\nhead(fc$implications$filter(rhs = \"fake\"))\n\nImplication set with 6 implications.\nRule 1: {no.profile.pic, no.has.description} -&gt; {fake}\nRule 2: {no.profile.pic, no.private} -&gt; {fake}\nRule 3: {has.nums.fullname, no.profile.pic} -&gt; {fullname.words = [1, 2], fake}\nRule 4: {X.follows = &lt; 20, no.profile.pic} -&gt; {fake}\nRule 5: {X.follows = [20, 200], no.profile.pic} -&gt; {fake}\nRule 6: {X.follows = [20, 200], has.nums.fullname} -&gt; {fullname.words = [1, 2],\n  fake}\n\n\nEncontramos el mismo conocimiento que con arules.\nCon las implicaciones también podemos calcular el cierre de atributos (también podemos con los objetos, pero en este caso no nos interesa pues lo único que podemos sacar es el número de cuentas que habría en el cierre, cada cuenta no tiene nada que la haga especial o distinta de las demás).\n\nprofile.pic\n\n\nS &lt;- Set$new(attr_ig)\nS$assign(c(\"no.profile.pic\", \"no.fake\"), values = 1)\nfc$implications$closure(S)\n\n$closure\n{nums.length.username = 0, private, X.followers = &gt; 200, X.follows = &gt; 200,\n  has.description, no.fake, no.profile.pic, no.name..username, no.external.URL,\n  no.has.nums.fullname}\n\n\nEl cierre de no tener foto y ser una cuenta real, es: - no tener números en el nombre de usuario, ser privada, tener más de 200 seguidores, seguir a más de 200 personas, tener desripción, tener el nombre real distinto del nombre de usuario, no tener enlace externo y no tener números en el nombre real."
  },
  {
    "objectID": "formal_concept_analysis.html#conclusiones",
    "href": "formal_concept_analysis.html#conclusiones",
    "title": "5  FCA",
    "section": "5.5 Conclusiones",
    "text": "5.5 Conclusiones\nFCA es una herramienta poderosa para identificar y visualizar relaciones en conjuntos de datos, permitiendo la detección de patrones y la extracción de conocimiento valioso. FCA nos ha facilitado la diferenciación entre cuentas auténticas y falsas, identificando grupos con características comunes. Hemos necesitado realizar un trabajo de de preprocesamiento como el que hiicmos para las reglas de asociación, con lo que hemos obtenido variables binarias y nominales que hemos usado para crear nuestros conceptos.\nEl uso de fcaR para generar conceptos y reglas de implicación muestra cómo se pueden descubrir asociaciones no triviales, proporcionando una visión profunda de los datos.\nCon toda la información que hemos obtenido hasta ahora, estamos listos para realizar regresión, una técnica que nos permitirá realizar predicciones sobre la veracidad o falsedad de las cuentas de Instagram."
  },
  {
    "objectID": "regression.html#primeros-pasos",
    "href": "regression.html#primeros-pasos",
    "title": "6  Regresión",
    "section": "6.1 Primeros pasos",
    "text": "6.1 Primeros pasos\nPara las técnicas de regresión es importante que todas nuestras variables sean numéricas. No podemos hacer un ajuste con carácteres. Si fuese el caso, podríamos hacer de nuevo un trabajo de pre-processing, pero por suerte:\n\nstr(dataset)\n\n'data.frame':   576 obs. of  12 variables:\n $ profile.pic         : int  1 1 1 1 1 1 1 1 1 1 ...\n $ nums.length.username: num  0.27 0 0.1 0 0 0 0 0 0 0 ...\n $ fullname.words      : int  0 2 2 1 2 4 2 2 0 2 ...\n $ nums.length.fullname: num  0 0 0 0 0 0 0 0 0 0 ...\n $ name..username      : int  0 0 0 0 0 0 0 0 0 0 ...\n $ description.length  : int  53 44 0 82 0 81 50 0 71 40 ...\n $ external.URL        : int  0 0 0 0 0 1 0 0 0 1 ...\n $ private             : int  0 0 1 0 1 0 0 0 0 0 ...\n $ X.posts             : int  32 286 13 679 6 344 16 33 72 213 ...\n $ X.followers         : int  1000 2740 159 414 151 669987 122 1078 1824 12945 ...\n $ X.follows           : int  955 533 98 651 126 150 177 76 2713 813 ...\n $ fake                : int  0 0 0 0 0 0 0 0 0 0 ...\n\n\n¡Nuestro dataset tiene todas las variables númericas! Probablemente con regresión tengamos más juego que con FCA.\nAunque no todo es bueno. La variable que queremos predecir, fake, es una variable binaria, y la regresión no es lo más ideal para predecir exactamente entre dos valores.\nVamos a intentar sacar el mayor conocimiento de nuestros datos y encontrar ajustes interesantes."
  },
  {
    "objectID": "regression.html#primeras-regresiones",
    "href": "regression.html#primeras-regresiones",
    "title": "6  Regresión",
    "section": "6.2 Primeras regresiones",
    "text": "6.2 Primeras regresiones\nAunque lo que queremos es predecir la variable “fake”, es bueno antes de comenzar ver relaciones entre otras variables, y particularmente que variables se relacionan más con fake.\nEn el análisis exploratorio, construimos una tabla que nos proporcionaba las mayores relaciones entre variables. Vamos a recuperar dicha tabla:\n\nthreshold &lt;- 0.4\n\ncor_table &lt;- data.frame(as.table(cor(dataset))) %&gt;% \n  rename(Correlation = Freq)\n\nvariables &lt;- colnames(dataset)\nn_variables &lt;- length(dataset)\n\n# Para que no haya repeticiones simétricas, vamos a poner la restricción de que el \n# orden léxicográfico de una variable sea mayor (o menor) que la otra. \n# Con un != no valdría porque habría valores filas simétricas\ncor_table %&gt;% \n  filter(as.character(Var1) &gt; as.character(Var2) & abs(Correlation) &gt; threshold) %&gt;%\n  arrange(desc(abs(Correlation)))\n\n                  Var1                 Var2 Correlation\n1          profile.pic                 fake  -0.6373153\n2 nums.length.username                 fake   0.5876865\n3         external.URL   description.length   0.4823131\n4                 fake   description.length  -0.4608246\n5 nums.length.username nums.length.fullname   0.4085665\n\n\nVemos que la mayor correlación (aunque inversa, pero eso no nos importa, lo importante es que hay relación para la regresión). El problema con el que nos encontraremos más adelante, es que estas variables son binarias.\nPodemos ir intuyendo que si queremos ajustar una variable a partir de una variable binaria, como dicha variable solo puede tomar dos valores, por muy complejo que sea el ajuste, solo hay dos posibles resultados. Como la variable que también queremos predecir es binaria, solo nos queda asignar un valor de la variable usada en el ajuste para un valor de la variable fake, pero obviamente esto no es un buen modelo.\nVamos a intentar hacer una regresión simple entre estas dos variables.\n\nmodelo1 &lt;- lm(fake ~ profile.pic, data = dataset)\nsummary(modelo1)\n\n\nCall:\nlm(formula = fake ~ profile.pic, data = dataset)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.98837 -0.29208 -0.14023  0.01163  0.70792 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.98837    0.02943   33.58   &lt;2e-16 ***\nprofile.pic -0.69629    0.03514  -19.81   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.386 on 574 degrees of freedom\nMultiple R-squared:  0.4062,    Adjusted R-squared:  0.4051 \nF-statistic: 392.6 on 1 and 574 DF,  p-value: &lt; 2.2e-16\n\n\nObtenemos un 0.40 de R^2 ajustado, lo que no está tan mal para la simplicidad del modelo.\nLos únicos dos valores que puede dar como predicción nuestro modelo son:\n\nunique(predict(modelo1))\n\n[1] 0.2920792 0.9883721\n\n\nA nosotros nos interesa un valor de 0 o un valor 1, así que podemos decir que el 0.29 es 0, por cercanía, y el 0.98 es 1. Construyamos una tabla:\n\npredicciones &lt;- predict(modelo1)\npredicciones_binarizado &lt;- ifelse(predicciones &lt; 0.3, 0, 1)\n\ntabla &lt;- data.frame(profile.pic=dataset$profile.pic,\n           fake=dataset$fake,\n           prediccion=predicciones,\n           prediccion_bin=predicciones_binarizado)\n\nhead(tabla, 10)\n\n   profile.pic fake prediccion prediccion_bin\n1            1    0  0.2920792              0\n2            1    0  0.2920792              0\n3            1    0  0.2920792              0\n4            1    0  0.2920792              0\n5            1    0  0.2920792              0\n6            1    0  0.2920792              0\n7            1    0  0.2920792              0\n8            1    0  0.2920792              0\n9            1    0  0.2920792              0\n10           1    0  0.2920792              0\n\n\nSi observamos lo que está pasando, es que nuestro modelo de regresión (junto a la binarización), para las cuentas con foto, predice que no es falsa, y para las cuentas sin foto, predice que es falsa.\nVamos a calcular el % de aciertos asumiendo lo anterior:\n\ntotal &lt;- nrow(dataset)\naciertos &lt;- sum(predicciones_binarizado == dataset$fake)\n\npaste0(\"Hemos obtenido un \", round(100*aciertos/total,2), \"% de aciertos\")\n\n[1] \"Hemos obtenido un 79.17% de aciertos\"\n\n\nParece un buen resultado, ¿verdad? Pues casi un 80% de aciertos es un buen modelo… ¿no?\nDebemos tener en cuenta que nuestro dataset es pequeño, y que queremos un modelo riguroso, no podemos basarnos en una sola característica para predecir si una cuenta de Instagram es falsa.\nSi concluyesemos que el modelo anterior es muy bueno, nuestro predictor se basaría simplemente en tener foto de perfil o no. Es demasiado básico. El porcentaje de aciertos viene de que en nuestro dataset esto es un patrón que suele aparecer, pero quizá si el dataset fuese mas grande, no aparecería:\n\ncasualidades &lt;- sum(dataset$profile.pic == !dataset$fake)\nround(100 * casualidades / total, 2)\n\n[1] 79.17\n\n\nDe ahí viene el porcentaje de aciertos.\nY aunque el patrón siguiese dándose en un dataset más grande, es un modelo demasiado simple, no podemos ir a alguien y decirle si su cuenta es falsa o no simplemente por si tiene foto de perfil.\nYa que es un ajuste bidimensional, pero si lo visualizamos, para que veamos que esto por si solo no es algo muy útil:\n\nggplot(dataset, aes(x = profile.pic, y = fake, color=\"red\")) +\n  geom_point() +\n  geom_line(y = predicciones, color =\"blue\") +\n  labs(title = \"Regresión lineal de fake sobre profile.pic\",\n       x = \"profile.pic\",\n       y = \"fake\") +\n  theme_minimal() \n\n\n\n\nLa función lineal que nos ha creado el modelo es (donde Y es fake y X es profile.pic):\n\npaste0(\"y = \", modelo1$coefficients[2], \"x + \", modelo1$coefficients[1])\n\n[1] \"y = -0.696292885102468x + 0.988372093023256\""
  },
  {
    "objectID": "regression.html#preparando-el-terreno",
    "href": "regression.html#preparando-el-terreno",
    "title": "6  Regresión",
    "section": "6.3 Preparando el terreno",
    "text": "6.3 Preparando el terreno\nYa hemos visto que predecir usando únicamente variables binarizadas no es una gran opción. También hemos visto, que dado que queremos ajustar una variable binaria (fake), los resultados que queremos son 0 o 1.\nPor lo que vamos a crear una serie de funciones con las que podamos binarizar nuestros resultados para probar nuestras predicciones, y también calcular valores estadísticos del modelo teniendo en cuenta esta binarización:\n\nFunción binarize.predictions Simplemente dado el conjunto de predicciones, las binariza usando cierto threshold, que por defecto será 0.5:\n\n\nbinarize.predictions &lt;- function(predictions, threshold=0.5) {\n  ifelse(predictions &lt; 0.5, 0, 1)\n}\n\n\nFunción aciertos.binarized Calcula el porcentaje de aciertos para nuestro dataset, binarizando los resultados\n\n\naciertos.binarized &lt;- function(predictions, real, threshold=0.5) {\n  total &lt;- length(real)\n  aciertos &lt;- sum(binarize.predictions(predictions) == real)\n  \n  100 * aciertos / total\n}\n\n\nFunción rss.binarized Calcula el RSS con las predicciones binarizadas\n\n\nrss.binarized &lt;- function(model, real, threshold=0.5) {\n  sum((real - binarize.predictions(predict(model), threshold))^2)\n}\n\n\nFunción rsquared.binarized Calcula el parámetro R^2 del modelo, pero usando las predicciones binarizadas (ya que el R^2 que nos proporciona summary, se realiza con los valores sin binarizar, y es un valor diferente)\n\n\nrsquared.binarized &lt;- function(model, real, threshold=0.5) {\n  rss &lt;- rss.binarized(model, real, threshold)\n  tss &lt;- sum((real - mean(real))^2)\n  \n  1 - (rss/tss)\n}\n\n\nFunción rse.binarized Lo mismo que con rsquared.binarized, pero para calcular RSE (residual standar error):\n\n\nrse.binarized &lt;- function(model, real, threshold=0.5) {\n  rss &lt;- rss.binarized(model, real, threshold)\n  n &lt;- length(real)\n  \n  rse &lt;- sqrt((1/(n-2))*rss) \n  \n  return(rse)\n}\n\n\nFunción fstatistic.binarized Calcula el F-statistic para las predicciones binarizadas:\n\n\nfstatistic.binarized &lt;- function(model, real) {\n  tss &lt;- sum((real - mean(real))^2)\n  rss &lt;- rss.binarized(model, real, threshold)\n\n  p &lt;- length(model$coefficients) - 1\n  n &lt;- length(real)\n  \n  ((tss - rss) / p) / (rss / (n - p - 1))\n}"
  },
  {
    "objectID": "regression.html#regresiones-previas",
    "href": "regression.html#regresiones-previas",
    "title": "6  Regresión",
    "section": "6.4 Regresiones previas",
    "text": "6.4 Regresiones previas\nVamos a intentar ahora ajustar ahora algunas de las variables que no son binarias entre sí, a ver si encontramos alguna relación interesante.\nPara no probar a lo loco, vamos a coger la tabla del principio pero esta vez la vamos a construir solo con variables que no sean binarias:\n\nunique_values &lt;- sapply(dataset, function(x) length(unique(x)))\nbinary_vars &lt;- names(which(unique_values == 2))\n\ncor_table %&gt;% \n  filter(as.character(Var1) &gt; as.character(Var2) \n         & !(Var1 %in% binary_vars)\n         & !(Var2 %in% binary_vars)) %&gt;%\n  arrange(desc(abs(Correlation)))\n\n                   Var1                 Var2  Correlation\n1  nums.length.username nums.length.fullname  0.408566542\n2               X.posts          X.followers  0.321385480\n3  nums.length.username   description.length -0.321170271\n4        fullname.words   description.length  0.272522165\n5             X.follows   description.length  0.226561422\n6  nums.length.username       fullname.words -0.225472125\n7             X.follows nums.length.username -0.172413275\n8               X.posts nums.length.username -0.157442112\n9               X.posts   description.length  0.144823702\n10 nums.length.fullname   description.length -0.117521050\n11              X.posts            X.follows  0.098225040\n12            X.follows       fullname.words  0.094854964\n13 nums.length.fullname       fullname.words -0.094347995\n14              X.posts       fullname.words  0.073350182\n15            X.follows nums.length.fullname -0.067971092\n16          X.followers nums.length.username -0.062785090\n17              X.posts nums.length.fullname -0.057715505\n18          X.followers       fullname.words  0.033224604\n19          X.followers nums.length.fullname -0.027034712\n20            X.follows          X.followers -0.011065994\n21          X.followers   description.length  0.005929455\n\n\nVamos a probar una regresión con el primer par de variables, para explorar como jugar con los datos, y luego pasaremos a intentar predecir la variable fake en función de todo lo demás:\n\nRegresión entre nums.length.username y nums.length.fullname\n\nPrimero vamos a visualizar la nube de puntos:\n\nggplot(dataset, aes(x=nums.length.username, y=nums.length.fullname)) +\n  geom_point()\n\n\n\n\nSe aprecia como hay muchos valores en nums.length.fullname = 0 (y = 0), y algunos en nums.length.username = 0 (x = 0) pero por lo demás, parece haber una clara tendencia lineal alcista.\nCreamos un modelo de regresión lineal, pues salvo los valores en los ejes, parece que la nube de puntos dibuja una línea:\n\nmodelo &lt;- lm(nums.length.fullname ~ nums.length.username, data = dataset)\n\n\nsummary(modelo)\n\n\nCall:\nlm(formula = nums.length.fullname ~ nums.length.username, data = dataset)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.21426 -0.05667  0.00303  0.00303  0.79291 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          -0.003026   0.005999  -0.504    0.614    \nnums.length.username  0.238772   0.022264  10.725   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1143 on 574 degrees of freedom\nMultiple R-squared:  0.1669,    Adjusted R-squared:  0.1655 \nF-statistic:   115 on 1 and 574 DF,  p-value: &lt; 2.2e-16\n\n\nEl R^2 es muy malo, un 0.16. Vamos a visualizar la regresión:\nVeamos los valores predichos en una tabla:\n\ntabla &lt;- data.frame(\n  nums.length.username=nums.length.username,\n  nums.length.fullname=nums.length.fullname,\n  prediccion=predict(modelo)\n)\n\nhead(tabla, 10)\n\n   nums.length.username nums.length.fullname   prediccion\n1                  0.27                    0  0.061442570\n2                  0.00                    0 -0.003025925\n3                  0.10                    0  0.020851295\n4                  0.00                    0 -0.003025925\n5                  0.00                    0 -0.003025925\n6                  0.00                    0 -0.003025925\n7                  0.00                    0 -0.003025925\n8                  0.00                    0 -0.003025925\n9                  0.00                    0 -0.003025925\n10                 0.00                    0 -0.003025925\n\n\n\nggplot(dataset, aes(x = nums.length.username, y = nums.length.fullname, color=\"red\")) +\n  geom_point() +\n  geom_line(aes(x = nums.length.username, y = predict(modelo), color =\"blue\")) +\n  labs(title = \"Regresión lineal de nums.length.fullname sobre nums.length.username\",\n       x = \"nums.length.username\",\n       y = \"nums.length.fullname\") +\n  theme_minimal() \n\n\n\n\nVemos que la línea se ve influenciada altamente por los valores en los ejes. Se trata de las cuentas sin números en el nombre completo pero con números en el nombre de usuario y viceversa.\nVamos a visualizar los gráficos que nos proporciona la función plot aplicada al modelo:\n\nplot(modelo)\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa primera gráfica es simplemente un gráfico entre los residuos y los valores predichos. Vemos que R nos marca algunos valores que están muy lejanos el gráfico, estos son outliers.\nEl segundo gráfico nos muestra un gráfico nos mostraría una linea reacta si los errores se distribuyesen de manera normal, lo que claramente no es el caso. Los outliers se desvian de dicha línea, y vemos que tenemos muchos valores que se desvian bastante, probablemente los valores de los ejes.\nLa tercera gráfica también marca outliers.\nLa cuarta y última muestra la distancia de Cook, que nos indica que puntos tienen una mayor influencia en la regresión. También marca los outliers.\nLo que nos recomienda lo anterior es eliminar esos valores marcados, pero vamos a eliminar todos los valores de los ejes, aunque sean bastantes, para intentar encontrar una relación entre las cuentas que tienen números en el nombre de usuario y nombre real, eliminando los que no tiene números en alguno de los.\nEliminamos outliers:\n\ndataset_modif &lt;- dataset %&gt;%\n  filter(nums.length.username &gt; 0 & nums.length.fullname &gt; 0)\n\nnrow(dataset_modif)\n\n[1] 52\n\n\nNos hemos quedado prácticamente con el 9% de los datos, la mayoría no tienen números en ambos nombres.\nVamos a realizar la predicción ahora:\n\nmodelo &lt;- lm(dataset_modif$nums.length.fullname ~ dataset_modif$nums.length.username, \n             data = dataset_modif)\n\n\nsummary(modelo)\n\n\nCall:\nlm(formula = dataset_modif$nums.length.fullname ~ dataset_modif$nums.length.username, \n    data = dataset_modif)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56406 -0.04487  0.01122  0.05000  0.23932 \n\nCoefficients:\n                                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                         0.02932    0.03803   0.771    0.444    \ndataset_modif$nums.length.username  0.83109    0.08301  10.012 1.54e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1191 on 50 degrees of freedom\nMultiple R-squared:  0.6672,    Adjusted R-squared:  0.6605 \nF-statistic: 100.2 on 1 and 50 DF,  p-value: 1.544e-13\n\n\nEl R^2 ha subido a 0.66, pero recordamos que hemos eliminado el 91% de los datos.\nVisualicemos:\n\ndata.frame(\n  nums.length.username=dataset_modif$nums.length.username,\n  nums.length.fullname=dataset_modif$nums.length.fullname,\n  prediccion=predict(modelo)\n)\n\n   nums.length.username nums.length.fullname prediccion\n1                  0.10                 0.10  0.1124314\n2                  0.24                 0.24  0.2287844\n3                  0.45                 0.25  0.4033138\n4                  0.22                 0.14  0.2121625\n5                  0.22                 0.22  0.2121625\n6                  0.44                 0.43  0.3950029\n7                  0.31                 0.36  0.2869609\n8                  0.33                 0.33  0.3035827\n9                  0.55                 0.29  0.4864231\n10                 0.11                 0.11  0.1207423\n11                 0.31                 0.31  0.2869609\n12                 0.89                 0.89  0.7689946\n13                 0.20                 0.20  0.1955407\n14                 0.38                 0.40  0.3451374\n15                 0.22                 0.22  0.2121625\n16                 0.24                 0.24  0.2287844\n17                 0.58                 0.36  0.5113559\n18                 0.33                 0.38  0.3035827\n19                 0.33                 0.33  0.3035827\n20                 0.31                 0.31  0.2869609\n21                 0.50                 0.33  0.4448685\n22                 0.33                 0.33  0.3035827\n23                 0.40                 0.40  0.3617592\n24                 0.43                 0.40  0.3866920\n25                 0.57                 0.40  0.5030450\n26                 0.29                 0.33  0.2703390\n27                 0.38                 0.33  0.3451374\n28                 0.33                 0.25  0.3035827\n29                 0.27                 0.27  0.2537172\n30                 0.28                 0.24  0.2620281\n31                 0.20                 0.33  0.1955407\n32                 0.50                 0.40  0.4448685\n33                 0.58                 0.44  0.5113559\n34                 0.22                 0.33  0.2121625\n35                 0.38                 0.33  0.3451374\n36                 0.88                 1.00  0.7606837\n37                 0.88                 1.00  0.7606837\n38                 0.33                 0.22  0.3035827\n39                 0.50                 0.50  0.4448685\n40                 0.25                 0.18  0.2370953\n41                 0.57                 0.57  0.5030450\n42                 0.46                 0.46  0.4116248\n43                 0.60                 0.50  0.5279778\n44                 0.46                 0.50  0.4116248\n45                 0.31                 0.31  0.2869609\n46                 0.43                 0.43  0.3866920\n47                 0.50                 0.40  0.4448685\n48                 0.86                 0.18  0.7440619\n49                 0.16                 0.12  0.1622970\n50                 0.92                 1.00  0.7939274\n51                 0.55                 0.44  0.4864231\n52                 0.38                 0.33  0.3451374\n\n\nY visualizamos:\n\nggplot(dataset_modif, aes(\n  x = nums.length.username, \n  y = nums.length.fullname, \n  color=\"red\")) +\n  geom_point() +\n  geom_line(aes(\n    x = nums.length.username, \n    y = predict(modelo), \n    color =\"blue\")) +\n  labs(title = \"Regresión lineal de nums.length.fullname sobre nums.length.username\",\n       x = \"nums.length.username\",\n       y = \"nums.length.fullname\") +\n  theme_minimal() \n\n\n\n\nEl ajuste es mucho mejor que el anterior, y eso que aún tenemos algún outlier como el que se ve abajo derecha.\nYa que hemos probado con estas dos variables estamos más que preparados para pasar a intentar predecir la variable importante, fake."
  },
  {
    "objectID": "regression.html#regresión-con-fake",
    "href": "regression.html#regresión-con-fake",
    "title": "6  Regresión",
    "section": "6.5 Regresión con fake",
    "text": "6.5 Regresión con fake\nYa hemos explorado suficiente, vamos a por lo grande.\nVamos a intentar predecir la variable fake a partir de las demás. Usando “.”, podemos ajustar la variable fake respecto a todas las demás. Veamos como queda dicho modelo.\n\nmodelo2 &lt;- lm(fake ~ ., data = dataset)\n\n\nsummary(modelo2)\n\n\nCall:\nlm(formula = fake ~ ., data = dataset)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.73096 -0.23729 -0.06653  0.24048  1.01052 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           7.931e-01  3.798e-02  20.880  &lt; 2e-16 ***\nprofile.pic          -4.380e-01  3.345e-02 -13.094  &lt; 2e-16 ***\nnums.length.username  8.062e-01  7.522e-02  10.718  &lt; 2e-16 ***\nfullname.words       -3.354e-02  1.333e-02  -2.516 0.012142 *  \nnums.length.fullname -2.775e-02  1.212e-01  -0.229 0.818988    \nname..username        2.241e-01  7.641e-02   2.933 0.003498 ** \ndescription.length   -1.510e-03  4.342e-04  -3.478 0.000544 ***\nexternal.URL         -1.542e-01  4.800e-02  -3.213 0.001390 ** \nprivate              -9.459e-03  2.843e-02  -0.333 0.739459    \nX.posts              -9.094e-05  3.570e-05  -2.547 0.011120 *  \nX.followers          -9.960e-09  1.539e-08  -0.647 0.517743    \nX.follows            -1.850e-05  1.499e-05  -1.235 0.217530    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3166 on 564 degrees of freedom\nMultiple R-squared:  0.6074,    Adjusted R-squared:  0.5998 \nF-statistic: 79.33 on 11 and 564 DF,  p-value: &lt; 2.2e-16\n\n\nNuestro modelo tiene un 0.6 de R^2, un error residual relativamente pequeño y un f-statistic mayor de 79.33. No está nada mal.\nVamos a ver el % de aciertos usando las funciones que creamos al principio.\n\naciertos.binarized(predict(modelo2), fake)\n\n[1] 89.93056\n\n\n!Casi un 90%¡. Parece que la regresión nos está dando buenos resultados, y eso que aún no hemos intentado mejorar el modelo.\nCalculemos el RSE, R^2 Y F-statistic estádisticos para nuestro modelo binarizado:\n\npaste(\"RSE:\", round(rse.binarized(modelo2, fake),4))\n\n[1] \"RSE: 0.3179\"\n\npaste(\"R2:\", round(rsquared.binarized(modelo2, fake),4))\n\n[1] \"R2: 0.5972\"\n\npaste(\"F-statistic:\", round(fstatistic.binarized(modelo2, fake),2))\n\n[1] \"F-statistic: 76.03\"\n\n\nLos valores de los estádisticos son prácticamente los mismos que para el modelo sin binarizar."
  },
  {
    "objectID": "regression.html#mejorando-el-modelo",
    "href": "regression.html#mejorando-el-modelo",
    "title": "6  Regresión",
    "section": "6.6 Mejorando el modelo",
    "text": "6.6 Mejorando el modelo\nSi hacemos summary\n\nsummary(modelo2)\n\n\nCall:\nlm(formula = fake ~ ., data = dataset)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.73096 -0.23729 -0.06653  0.24048  1.01052 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           7.931e-01  3.798e-02  20.880  &lt; 2e-16 ***\nprofile.pic          -4.380e-01  3.345e-02 -13.094  &lt; 2e-16 ***\nnums.length.username  8.062e-01  7.522e-02  10.718  &lt; 2e-16 ***\nfullname.words       -3.354e-02  1.333e-02  -2.516 0.012142 *  \nnums.length.fullname -2.775e-02  1.212e-01  -0.229 0.818988    \nname..username        2.241e-01  7.641e-02   2.933 0.003498 ** \ndescription.length   -1.510e-03  4.342e-04  -3.478 0.000544 ***\nexternal.URL         -1.542e-01  4.800e-02  -3.213 0.001390 ** \nprivate              -9.459e-03  2.843e-02  -0.333 0.739459    \nX.posts              -9.094e-05  3.570e-05  -2.547 0.011120 *  \nX.followers          -9.960e-09  1.539e-08  -0.647 0.517743    \nX.follows            -1.850e-05  1.499e-05  -1.235 0.217530    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3166 on 564 degrees of freedom\nMultiple R-squared:  0.6074,    Adjusted R-squared:  0.5998 \nF-statistic: 79.33 on 11 and 564 DF,  p-value: &lt; 2.2e-16\n\n\nVemos que tenemos varias variables con un p-value bastante alto. Estas variables añaden complejidad al modelo y no aportan nada, vamos a eliminarlas (creando un nuevo modelo sin ellas). Vamos a quedarnos con las variables que tienen un p-value menor a 0.01, es decir, profile.pic, nums.length.username, name..username, description.length y external.URL.\n\nmodelo3 &lt;- lm(fake ~ profile.pic + nums.length.username + name..username +  description.length + external.URL, data = dataset)\n\n\nsummary(modelo3)\n\n\nCall:\nlm(formula = fake ~ profile.pic + nums.length.username + name..username + \n    description.length + external.URL, data = dataset)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.71113 -0.24453 -0.07143  0.24282  0.98317 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.7354681  0.0316443  23.242  &lt; 2e-16 ***\nprofile.pic          -0.4596554  0.0328023 -14.013  &lt; 2e-16 ***\nnums.length.username  0.8445023  0.0687052  12.292  &lt; 2e-16 ***\nname..username        0.2314540  0.0733411   3.156 0.001685 ** \ndescription.length   -0.0017381  0.0004285  -4.056 5.68e-05 ***\nexternal.URL         -0.1731966  0.0477099  -3.630 0.000309 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3196 on 570 degrees of freedom\nMultiple R-squared:  0.5956,    Adjusted R-squared:  0.592 \nF-statistic: 167.9 on 5 and 570 DF,  p-value: &lt; 2.2e-16\n\n\nVemos que el R2 ha bajado un poco pero es prácticamente el mismo, al igual que RSE, que solo ha incrementado un poco, y sin embargo, el fstatistic ha incremetnado bastante.\nHemos conseguido unos resultados prácticamente idénticos, mejorando el fstatistic, y reduciendo considerablemente la complejidad del modelo.\n\naciertos.binarized(predict(modelo3), fake)\n\n[1] 89.93056\n\n\nLos aciertos son exactamente los mismos. Todas las variables que henmos eliminado no aportaban prácticamente nada.\nVeamos los gráficos que nos proporciona plot.\n\nplot(modelo3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAl estar intentando predecir una variable que solo toma dos valores, los gráficos son bastante más distintos de lo normal. Podemos apreciar que hay outliers, aunque no demasiados como cuando estabamos ajustando las variables nums.length.fullname y nums.length.username.\nAhora, vamos a intentar mejorar nuestro modelo añadiendo términos no lineales. Hay ciertas variables que quizá de la forma en que se nos presenta no aportan mucho a los datos, pero aplicandole alguna transformación, pueden aportar.\nCon solo términos lineales estamos ajustando un hiperplano de a nuestra nube de puntos de n dimensiones, pero con términos no lineales formamos figuras mas complejas que un hiper plano.\nVamos a añadir más términos. Para la descripción vamos a añadir términos elevados a 2, 3 y 4. Para los followers, que antes nos salía que no era una variable relevante, vamos a hacerle el logaritmo, ya que los valores crecían exponencialmente (para poder hacerle el logaritmo, tenemos que tener cuidado, pues hay valores con 0, así que simplemente sumamos 1) y por último vamos a hacerle la raíz cuadrada a X.follows.\n\nmodelo4 &lt;- update(modelo3, . ~ . + \n                    I(description.length^2) +\n                    I(description.length^3) +\n                    I(description.length^4) +\n                    I(log(X.followers+1)) +\n                    I(log(X.followers+1)^2) +\n                    I(log(X.followers+1)^3) +\n                    I(log(X.followers+1)^4) +\n                    I(log(X.followers+1)^2) +\n                    I(X.follows^0.5))\n\nSon términos “extraños” que nos hemos inventado, y como vamos a ver ahora, han provocado un ajuste bueno, pero hay que tener cuidado. Podríamos añadir todas las variables que queramos con todas las modificaciones que queramos, pero esto puede provocar un sobreajuste (overfitting).\nEl sobreajuste ocurre cuando entrenamos el modelo de forma que se adapta demasiado a los datos, sin tener ese grado de generalización que es lo que nos permite que dados nuevos datos, el modelo funcione correctamente.\nDe hecho, este último modelo, tiene cierto grado de sobreajuste, ya que hemos añadido variables que se adaptan demasiado a los datos.\nVamos a visualizar los estadísticos:\n\nsummary(modelo4)\n\n\nCall:\nlm(formula = fake ~ profile.pic + nums.length.username + name..username + \n    description.length + external.URL + I(description.length^2) + \n    I(description.length^3) + I(description.length^4) + I(log(X.followers + \n    1)) + I(log(X.followers + 1)^2) + I(log(X.followers + 1)^3) + \n    I(log(X.followers + 1)^4) + I(X.follows^0.5), data = dataset)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.70473 -0.18094 -0.02418  0.14988  0.82024 \n\nCoefficients:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                8.893e-01  5.802e-02  15.327  &lt; 2e-16 ***\nprofile.pic               -2.612e-01  3.073e-02  -8.498  &lt; 2e-16 ***\nnums.length.username       5.798e-01  6.141e-02   9.442  &lt; 2e-16 ***\nname..username             1.179e-01  6.220e-02   1.896  0.05847 .  \ndescription.length        -1.087e-02  3.774e-03  -2.879  0.00415 ** \nexternal.URL              -6.688e-02  4.343e-02  -1.540  0.12412    \nI(description.length^2)    2.864e-04  1.386e-04   2.067  0.03923 *  \nI(description.length^3)   -3.118e-06  1.616e-06  -1.929  0.05425 .  \nI(description.length^4)    1.150e-08  5.832e-09   1.972  0.04916 *  \nI(log(X.followers + 1))    1.934e-01  4.927e-02   3.925 9.73e-05 ***\nI(log(X.followers + 1)^2) -9.358e-02  1.450e-02  -6.455 2.33e-10 ***\nI(log(X.followers + 1)^3)  9.707e-03  1.493e-03   6.501 1.76e-10 ***\nI(log(X.followers + 1)^4) -2.979e-04  4.920e-05  -6.054 2.59e-09 ***\nI(X.follows^0.5)           4.795e-03  1.105e-03   4.341 1.68e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2678 on 562 degrees of freedom\nMultiple R-squared:   0.72, Adjusted R-squared:  0.7136 \nF-statistic: 111.2 on 13 and 562 DF,  p-value: &lt; 2.2e-16\n\n\nHemos obtenido un error residual de 0.26, un R^2 de 0.72 y un R^2 ajustado de 0.7136 (bastante cercano a 0.72, lo que indica que no tenemos mucha complejidad innecesaria, aunque). Vemos que el F-statistic si ha disminuido, a 111.2, aunque sigue siendo bastante alto.\nVeamos el porcentaje de aciertos:\n\naciertos &lt;- aciertos.binarized(predict(modelo4), fake)\npaste0(\"Hemos obtenido un \", round(aciertos, 2), \"% de aciertos\")\n\n[1] \"Hemos obtenido un 93.92% de aciertos\"\n\n\nCasi un 94%, nada mal, pero recordemos que estos son los mismos datos con los que hemos creado el modelo.\nVamos a ver los estadísticos binarizados:\n\npaste(\"RSE:\", round(rse.binarized(modelo4, fake),4))\n\n[1] \"RSE: 0.2469\"\n\npaste(\"R2:\", round(rsquared.binarized(modelo4, fake),4))\n\n[1] \"R2: 0.7569\"\n\npaste(\"F-statistic:\", round(fstatistic.binarized(modelo4, fake),2))\n\n[1] \"F-statistic: 134.63\"\n\n\nSon incluso mejores, y eso que estos son los reales, ya que como explicamos, nos interesan los datos binarizados, no la predicción que es resultado directo de la regresión. Parece ser que hemos encontrado un buen modelo a pesar de que nuestra predicción es binaria.\nVamos a pasar a la última fase, probar nuestros modelos."
  },
  {
    "objectID": "regression.html#modelos-finales",
    "href": "regression.html#modelos-finales",
    "title": "6  Regresión",
    "section": "6.7 Modelos finales",
    "text": "6.7 Modelos finales\nA modo de resumen, estos son los 4 modelos con los que nos hemos quedado (que predicen la variable fake) y a los que les haremos pruebas:\n\nmodelo1\n\nModelo de regresión lineal básico que simplemente usaba para predecir fake, la variable binaria profile.pic:\n\nsummary(modelo1)\n\n\nCall:\nlm(formula = fake ~ profile.pic, data = dataset)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.98837 -0.29208 -0.14023  0.01163  0.70792 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.98837    0.02943   33.58   &lt;2e-16 ***\nprofile.pic -0.69629    0.03514  -19.81   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.386 on 574 degrees of freedom\nMultiple R-squared:  0.4062,    Adjusted R-squared:  0.4051 \nF-statistic: 392.6 on 1 and 574 DF,  p-value: &lt; 2.2e-16\n\n\nEstadísticos con la binarización de los resultados:\n\npaste(\"RSE:\", round(rse.binarized(modelo1, fake),4))\n\n[1] \"RSE: 0.4572\"\n\npaste(\"R2:\", round(rsquared.binarized(modelo1, fake),4))\n\n[1] \"R2: 0.1667\"\n\npaste(\"F-statistic:\", round(fstatistic.binarized(modelo1, fake),2))\n\n[1] \"F-statistic: 114.8\"\n\n\n\nmodelo2\n\nModelo de regresión generalizado usando todas las variables del dataset, al que no se le ha hecho ningún estudio ni ninguna merjora:\n\nsummary(modelo2)\n\n\nCall:\nlm(formula = fake ~ ., data = dataset)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.73096 -0.23729 -0.06653  0.24048  1.01052 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           7.931e-01  3.798e-02  20.880  &lt; 2e-16 ***\nprofile.pic          -4.380e-01  3.345e-02 -13.094  &lt; 2e-16 ***\nnums.length.username  8.062e-01  7.522e-02  10.718  &lt; 2e-16 ***\nfullname.words       -3.354e-02  1.333e-02  -2.516 0.012142 *  \nnums.length.fullname -2.775e-02  1.212e-01  -0.229 0.818988    \nname..username        2.241e-01  7.641e-02   2.933 0.003498 ** \ndescription.length   -1.510e-03  4.342e-04  -3.478 0.000544 ***\nexternal.URL         -1.542e-01  4.800e-02  -3.213 0.001390 ** \nprivate              -9.459e-03  2.843e-02  -0.333 0.739459    \nX.posts              -9.094e-05  3.570e-05  -2.547 0.011120 *  \nX.followers          -9.960e-09  1.539e-08  -0.647 0.517743    \nX.follows            -1.850e-05  1.499e-05  -1.235 0.217530    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3166 on 564 degrees of freedom\nMultiple R-squared:  0.6074,    Adjusted R-squared:  0.5998 \nF-statistic: 79.33 on 11 and 564 DF,  p-value: &lt; 2.2e-16\n\n\nEstadísticos con la binarización de los resultados:\n\npaste(\"RSE:\", round(rse.binarized(modelo2, fake),4))\n\n[1] \"RSE: 0.3179\"\n\npaste(\"R2:\", round(rsquared.binarized(modelo2, fake),4))\n\n[1] \"R2: 0.5972\"\n\npaste(\"F-statistic:\", round(fstatistic.binarized(modelo2, fake),2))\n\n[1] \"F-statistic: 76.03\"\n\n\n\nmodelo3\n\nEs el modelo2 pero eliminando todas las variables que solo aportaban complejidad al modelo y prácticamente nada de información:\n\nsummary(modelo3)\n\n\nCall:\nlm(formula = fake ~ profile.pic + nums.length.username + name..username + \n    description.length + external.URL, data = dataset)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.71113 -0.24453 -0.07143  0.24282  0.98317 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           0.7354681  0.0316443  23.242  &lt; 2e-16 ***\nprofile.pic          -0.4596554  0.0328023 -14.013  &lt; 2e-16 ***\nnums.length.username  0.8445023  0.0687052  12.292  &lt; 2e-16 ***\nname..username        0.2314540  0.0733411   3.156 0.001685 ** \ndescription.length   -0.0017381  0.0004285  -4.056 5.68e-05 ***\nexternal.URL         -0.1731966  0.0477099  -3.630 0.000309 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3196 on 570 degrees of freedom\nMultiple R-squared:  0.5956,    Adjusted R-squared:  0.592 \nF-statistic: 167.9 on 5 and 570 DF,  p-value: &lt; 2.2e-16\n\n\nEstadísticos con la binarización de los resultados:\n\npaste(\"RSE:\", round(rse.binarized(modelo3, fake),4))\n\n[1] \"RSE: 0.3179\"\n\npaste(\"R2:\", round(rsquared.binarized(modelo3, fake),4))\n\n[1] \"R2: 0.5972\"\n\npaste(\"F-statistic:\", round(fstatistic.binarized(modelo3, fake),2))\n\n[1] \"F-statistic: 169.03\"\n\n\n\nmodelo4\n\nModelo de regresión generalizado no lineal. Resultado de añadir varaibles con logaritmos, exponentes y raices al modelo3.\n\nsummary(modelo1)\n\n\nCall:\nlm(formula = fake ~ profile.pic, data = dataset)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.98837 -0.29208 -0.14023  0.01163  0.70792 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.98837    0.02943   33.58   &lt;2e-16 ***\nprofile.pic -0.69629    0.03514  -19.81   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.386 on 574 degrees of freedom\nMultiple R-squared:  0.4062,    Adjusted R-squared:  0.4051 \nF-statistic: 392.6 on 1 and 574 DF,  p-value: &lt; 2.2e-16\n\n\nEstadísticos con la binarización de los resultados:\n\npaste(\"RSE:\", round(rse.binarized(modelo4, fake),4))\n\n[1] \"RSE: 0.2469\"\n\npaste(\"R2:\", round(rsquared.binarized(modelo4, fake),4))\n\n[1] \"R2: 0.7569\"\n\npaste(\"F-statistic:\", round(fstatistic.binarized(modelo4, fake),2))\n\n[1] \"F-statistic: 134.63\""
  },
  {
    "objectID": "regression.html#pruebas",
    "href": "regression.html#pruebas",
    "title": "6  Regresión",
    "section": "6.8 Pruebas",
    "text": "6.8 Pruebas\nHasta ahora, los porcentajes de aciertos que hemos calculado, son sobre nuestro dataset de entrenamiento, es decir, usamos unos datos para crear un modelo y luego lo probamos con los mismos datos. Esto no es realista, necesitamos otros datos para probar realmente nuestro modelo.\nDel sitio web de Kaggle, además del dataset “train.csv”, se encuentra “test.csv”. Vamos a utilizarlo para probar nuestros modelos, ya que probarlo con el mismo train.csv no es real, pues es la misma información que hemos usado para construir los modelos.\nImportamos el dataset\n\ndataset_test &lt;- read.csv(\"datasets/test.csv\")\n\nEste dataset contiene las mismas variables que train.csv:\n\ncolnames(dataset_test)\n\n [1] \"profile.pic\"          \"nums.length.username\" \"fullname.words\"      \n [4] \"nums.length.fullname\" \"name..username\"       \"description.length\"  \n [7] \"external.URL\"         \"private\"              \"X.posts\"             \n[10] \"X.followers\"          \"X.follows\"            \"fake\"                \n\n\n\nnrow(dataset_test)\n\n[1] 120\n\n\nTenemos 120 observaciones, la mitad clasificadas como falsas y la otra mitad como reales. Son observaciones distintas a las del dataset train.csv.\nVamos a calcular el porcentaje de aciertos en el dataset de pruebas usando cada modelo:\n\nmodelo1\n\n\npredicciones &lt;- predict(modelo1, dataset_test)\n\naciertos_test &lt;- aciertos.binarized(predicciones, dataset_test$fake)\naciertos_train &lt;- aciertos.binarized(predict(modelo1, dataset), dataset$fake)\n\npaste0(\"El modelo1 ha obtenido un \", round(aciertos_test, 2), \n       \"% de aciertos en el dataset de pruebas\")\n\n[1] \"El modelo1 ha obtenido un 74.17% de aciertos en el dataset de pruebas\"\n\n\n\n\n[1] \"Mientras que en el dataset de entrenamiento obtuvo un 79.17% de aciertos\"\n\n\nEste modelo depende totalmente de la foto de perfil. Es demasiado simple y como vemos con el test de pruebas ha perdido un 5% de aciertos. No es un buen modelo por su simplicidad y dependencia total en una única variable.\n\nmodelo2\n\n\npredicciones &lt;- predict(modelo2, dataset_test)\n\naciertos_test &lt;- aciertos.binarized(predicciones, dataset_test$fake)\naciertos_train &lt;- aciertos.binarized(predict(modelo2, dataset), dataset$fake)\n\npaste0(\"El modelo2 ha obtenido un \", round(aciertos_test, 2), \n       \"% de aciertos en el dataset de pruebas\")\n\n[1] \"El modelo2 ha obtenido un 89.17% de aciertos en el dataset de pruebas\"\n\n\n\n\n[1] \"Mientras que en el dataset de entrenamiento obtuvo un 89.93% de aciertos\"\n\n\nResultados casi iguales. No es un mal modelo pero es mejorable, como vemos con el modelo3, ya que podemos simplificar su complejidad.\n\nmodelo3\n\n\npredicciones &lt;- predict(modelo3, dataset_test)\n\naciertos_test &lt;- aciertos.binarized(predicciones, dataset_test$fake)\naciertos_train &lt;- aciertos.binarized(predict(modelo3, dataset), dataset$fake)\n\npaste0(\"El modelo3 ha obtenido un \", round(aciertos_test, 2), \n\"% de aciertos en el dataset de pruebas\")\n\n[1] \"El modelo3 ha obtenido un 89.17% de aciertos en el dataset de pruebas\"\n\n\n\n\n[1] \"Mientras que en el dataset de entrenamiento obtuvo un 89.93% de aciertos\"\n\n\nExactamente los mismos resultados que con el modelo2, lo que nos indica que la simplificación que hemos hecho respecto al modelo2 es muy buena.\n\nmodelo4\n\n\npredicciones &lt;- predict(modelo4, dataset_test)\n\naciertos_test &lt;- aciertos.binarized(predicciones, dataset_test$fake)\naciertos_train &lt;- aciertos.binarized(predict(modelo4, dataset), dataset$fake)\n\npaste0(\"El modelo4 ha obtenido un \", round(aciertos_test, 2), \n       \"% de aciertos en el dataset de pruebas\")\n\n[1] \"El modelo4 ha obtenido un 93.33% de aciertos en el dataset de pruebas\"\n\n\n\n\n[1] \"Mientras que en el dataset de entrenamiento obtuvo un 93.92% de aciertos\"\n\n\nUnos resultados muy buenos. Vemos que no tenemos mucho sobreajuste a pesar de que añadimos bastantes variables con exponentes y logaritmos. Es un buen modelo y el mejor de todos los que hemos hecho."
  },
  {
    "objectID": "regression.html#conclusiones",
    "href": "regression.html#conclusiones",
    "title": "6  Regresión",
    "section": "6.9 Conclusiones",
    "text": "6.9 Conclusiones\nHemos explorado el la regresión como técnica estadística para modelar y predecir la veracidad o falsedad de cuentas de Instagram. A lo largo del análisis, hemos hecho múltiples regresiones.\nAunque la variable fake es binaria, con la regresión hemos podido aproximar su valor con cierto grado de precisión.\nVeíamos como el primer modelo, aunque tenía un prácticamente un 80% de aciertos, era demasiado simple y no podíamos guiarnos por algo tan simple. Luego hicimos modelos más complejos y los simplificamos, hasta llegar a uno que nos daba unos valores estadísticos relativamente buenos.\nEl modelo4 ha resultado ser el mejor al incorporar términos no lineales y transformaciones logarítmicas y cuadráticas, con casi un 94% de aciertos en el dataset de entrenamiento. Aún así, este modelo mostró ciertos signos de sobreajuste (al bajar su f-statistic respecto al modelo3 mientras subía su R^2). Esto destaca la importancia de equilibrar la complejidad del modelo con su capacidad de generalización.\nExisten otras técnicas de regresión más complejas, y otros métodos de realizar el entrenamiento, como la validación cruzada, pero en este apartado, nos hemos centrado en intentar conseguir el mejor modelo a partir de lo visto en clase."
  },
  {
    "objectID": "temporal_series.html#serie-temporal-con-description.length",
    "href": "temporal_series.html#serie-temporal-con-description.length",
    "title": "7  Series temporales",
    "section": "7.1 Serie temporal con description.length",
    "text": "7.1 Serie temporal con description.length\nVamos a usar esta variable para crear nuestras series temporales, como hemos comentado, los datos no tienen ningún orden ni tenemos otras variables que representen tiempo, pero vamos a intentar aplicar algunas cosas de lo aprendido a esta variable para que veamos si se puede sacar algo de informcion.\nCreamos la serie temporal, imaginando que empieza en el año 2000 y cada dato representa un mes del año:\n\nserie &lt;- ts(dataset$description.length, frequency = 12, start = 2000)\nserie\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2000  53  44   0  82   0  81  50   0  71  40  54  54\n2001   0 103  98  46   0  48  63 106  40  35  30  27\n2002   0 109   0 132 126 122 138   0  50  35  56   9\n2003   0  81 134   0   2   0  23 138  35  93   4   1\n2004   4  23  91  57 108  30  82  12  54   0  12   0\n2005   3  39   0  68 129  57  64  42  71   0  70  74\n2006   8  35   0   0  28  18  28  36   2  11  70  29\n2007  24  21  81  34  40  12   0  59  15  54  16  73\n2008  24   0  26   0   0   0   0  28  55 140 122 113\n2009  38   0  23   0  89  30   0   0   0  12 123   0\n2010   0   0  40   0  33   0   5   0  23  35 150  26\n2011 149 129   0  18  74   0  59 148   0  15  46   5\n2012  98  55  19  71 133 150  43  37  35  87  59   0\n2013   0   9  12   0   0  95   0  46 123 117  26   0\n2014  58   0  30  62 137 149  14  19 131   0   5   0\n2015  11   0  27  10  72   3  51  44   0  73  70  35\n2016  13 105  91   0  48  48 126   0  53   8  67  20\n2017  26  86  51  26  18  96  17   0  62  86 148   1\n2018  39  35 103   0  61  44   0   0   0 112 123  24\n2019  34  19   0  42  50  67 134 101   0   0  17   0\n2020  32   0  80   2   0 146   0   0   0   0   6   0\n2021   0   0  64   0   0   0  49  23 120  34  25   0\n2022  12   0   9   1  18  34  23  19 139  13  50  46\n2023  30  26   0   0   0  27  37  31  20   7   0   0\n2024   0   0   0   0  24   0  43   0   0   0   0   0\n2025   0   0   0   0   0   0   0   0   0   0   0   0\n2026   0   0   0   0   0   0  43   0   0   0  13   0\n2027   0   0   0   0   0   0   0   0   0   0   0   0\n2028   0   0   0   0   0   0   9   0   0   0   0  18\n2029   0  10  61   0   0   0   0   0   0   0   0   0\n2030  22   0   0   0   2   0 146   0   6  50   0   0\n2031   0  39   0   0   0   0   0   5  91   2   0   0\n2032   0   0  37   0   0   0   0   0   0   0   0   0\n2033   0   0 148   0   0   0   0   0   0   0   0   0\n2034   0   0   0   0   0   0 149   0   0   0   0   0\n2035  22   0   0   0   0   0   2   0   0   0   0   0\n2036   0  20   0   0   0   0   0   0   0   0 148   0\n2037  50   0   2   0   0   0   0   0   0   0  34   0\n2038   0   0   0   0   0   0  32   0   0   0   0   0\n2039   0   0  59   0   6   0   0   0   0   0   0   0\n2040   0   0   0   0   0   0   0   0   0   0   0   0\n2041   0   1   0   0   0   0   0   0   0   0   0   0\n2042   0   0   0   0   0   0   0   0   0   0   0   0\n2043   0   0   0   0   0   0   0   0   0   0   0   0\n2044   0   0   0   0   0   0   0  19   0   0   0   0\n2045   0   0   0   0  43   0   0   0   0   0   0   0\n2046   0   0   0   0   0   0   0  33   0   0   0   0\n2047  43   0  19   0   5   0  28   0  21   0  11   0\n\n\n\nlength(serie)\n\n[1] 576\n\n\nComo tenemos 576 datos y hemos simulado que cada uno corresponde a un mes del año, empezando en el año 2000 nos da por resultado que nuestros datos llegan hasta el año 2047.\nVamos a ver nuestra serie dibujado:\n\nplot.ts(serie)\n\n\n\n\nComo podemos ver es bastante aleatorio, ya que realmente lo es, se trata de las longitudes de descripción de distintas cuentas de Instagram sin ningún orden ni nada de carácter temporal.\nCon autoplot podemos visualizar el mismo gráfico pero con un estilo similar a la filosofia que sigue ggplot2:\n\nautoplot(serie)\n\n\n\n\nVeamos el gráfico de seasonplot, el cual nos permite observar si nuestra serie temporal es estacional. Este gráfico muestra si cada año se repiten patrones específicos, ayudándonos a identificar y visualizar la estacionalidad en la serie temporal.\n\nggseasonplot(serie, col = rainbow(12), year.labels = TRUE)\n\n\n\n\nClaramente no muestra signos de estacionalidad, pues es prácticamente aleatorio, no hay ningún tipo de patrón."
  },
  {
    "objectID": "temporal_series.html#previsiones",
    "href": "temporal_series.html#previsiones",
    "title": "7  Series temporales",
    "section": "7.2 Previsiones",
    "text": "7.2 Previsiones\nVamos a probar a realizar previsiones con los métodos básicos que hemos visto. Estos métodos de por si son demasiado sencillos, y para el caso de nuestra serie que venimos diciendo que no es adecuada, sabemos que no va a dar ningún resultado bueno, pero vamos a aplicarlos para que lo veamos. Luego usaremos algunos métodos más complejos:\n\n7.2.1 Método de la media\n\navg.serie &lt;- meanf(serie, 10)\nplot(avg.serie)\n\n\n\n\n\n\n7.2.2 Método naive\n\nnaive.serie &lt;- naive(serie, 10)\nplot(naive.serie)\n\n\n\n\n\n\n7.2.3 Método naive estacional\n\nsnaive.serie &lt;- snaive(serie, 10)\nplot(snaive.serie)\n\n\n\n\n\n\n7.2.4 Método drift\n\nrwf.serie &lt;- rwf(serie, 20, drift = TRUE)\nplot(rwf.serie)\n\n\n\n\nComo hemos comentado, ningún método da una previsión que tenga coherencia, tan solo el método naive estacional, aunque ya sabemos que este solo replica la predicción del año anterior."
  },
  {
    "objectID": "temporal_series.html#descomposición",
    "href": "temporal_series.html#descomposición",
    "title": "7  Series temporales",
    "section": "7.3 Descomposición",
    "text": "7.3 Descomposición\nUna serie temporal se puede descomponer en tres componentes: estacional, tendencia y la componente de aleatoriedad.\nVamos a aplicar la descomposición a nuestra serie:\n\ndecomp &lt;- decompose(serie)\n\nVamos a visualizarlo:\n\nplot(decomp)\n\n\n\n\nSi nuestra serie fuese realmente una serie válida, estaríamos observando datos interesantes, por ejemplo, podríamos decir que la tendencia global de la longitud de la descripción ha sido bajista, y que tenemos una componente estacionaria en la que hay ciertos momentos del año que hay un pico alto y otros muy bajos.\nPero como el tiempo aquí “nos lo hemos inventando” sacar esas conclusiones es también inventarnoslo."
  },
  {
    "objectID": "temporal_series.html#previsiones-complejas",
    "href": "temporal_series.html#previsiones-complejas",
    "title": "7  Series temporales",
    "section": "7.4 Previsiones complejas",
    "text": "7.4 Previsiones complejas\nPor útimo, vamos a utilizar métodos más avanzados de previsiones, simplemente para visualizar los resultados.\n\n7.4.1 HoltWinters\nEl método Holt-Winters es una técnica de suavizamiento exponencial que permite modelar y prever series temporales con tendencia y estacionalidad. Este método tiene tres componentes: el nivel (alpha), la tendencia (beta) y la estacionalidad (gamma). Es bueno usarlo en series temporales con tendencia y estacionalidad o con patrones estacionalides conocidos.\nVamos a aplicarlo a nuestra serie temporal:\n\nts.p1.forecasts &lt;- HoltWinters(serie, beta = FALSE, gamma = FALSE)\nplot(ts.p1.forecasts)\n\n\n\n\nVisualicemos una predicción de un año:\n\nholtwinters_forecast &lt;- forecast(ts.p1.forecasts, h = 12)\nplot(holtwinters_forecast)\n\n\n\n\n\n\n7.4.2 ARIMA y auto.arima\nARIMA (AutoRegressive Integrated Moving Average) es un modelo popular en el análisis de series temporales, utilizado para modelar y prever series que pueden no ser estacionarias. El modelo ARIMA se define por tres parámetros: p (autoregresivo), d (diferenciación) y q (media móvil). El método auto.arima selecciona automáticamente los mejores parámetros para el modelo ARIMA. Es bueno usar ARIMA para series temporales estacionarias.\nAplicamos el modelo auto.arima a nuestra serie temporal:\n\nautoarima_model &lt;- auto.arima(serie)\nplot(forecast(autoarima_model, h = 20))\n\n\n\n\nQueda más que claro que lo que estamos haciendo no conduce a resultados con sentido, hay muchas más cosas que podemos hacer con series temporales, pero sabiendo que no nos conducen a nada, vamos a parar aquí."
  },
  {
    "objectID": "temporal_series.html#conclusiones",
    "href": "temporal_series.html#conclusiones",
    "title": "7  Series temporales",
    "section": "7.5 Conclusiones",
    "text": "7.5 Conclusiones\nEn este análisis, hemos aplicado varias técnicas de previsión de series temporales, como Holt-Winters y ARIMA, a una variable que en realidad no tiene un carácter temporal. Aunque hemos visto cómo se pueden usar estas técnicas, los resultados no tienen sentido práctico en este caso, ya que la serie de datos es aleatoria y no presenta patrones temporales reales.\nSin embargo, es importante comprender y saber aplicar estas técnicas, ya que son herramientas muy valiosas en el análisis de datos cuando se dispone de series temporales con componentes significativos de tendencia y estacionalidad."
  },
  {
    "objectID": "other_techniques.html#análisis-de-redes-sociales",
    "href": "other_techniques.html#análisis-de-redes-sociales",
    "title": "8  Otras técnicas",
    "section": "8.1 Análisis de redes sociales",
    "text": "8.1 Análisis de redes sociales\nCiertos datos tienen relaciones entre sí, como por ejemplo, los aeropuertos y los vuelos que se pueden realizar entre ellos en determinado país, ciudad, o en el mundo en general. Estos datos se pueden representar mediante grafos, donde los vértices serían los aeropuertos y los arcos, los vuelos.\nCon esta representación de datos, se pueden analizar de forma eficiente las relaciones y estructuras subyacentes. Por ejemplo, podemos identificar los aeropuertos más centrales utilizando medidas como el grado de centralidad, que nos indica cuántos vuelos salen o llegan a un aeropuerto en particular. Además, podemos aplicar algoritmos para detectar comunidades dentro de la red, revelando agrupaciones de aeropuertos que tienen más conexiones entre sí que con otros grupos.\nLos grafos abren un nuevo mundo de posibilidades y de algoritmos, es un área de estudio que se encuentra en la mayoría de cosas que hacemos cotidianamente.\nLamentablemente, nuestros datos carecen de relaciones, no tenemos ninguna relación entre cada par de observaciones de nuestro dataset, por lo que no podemos modelar de ninguna forma nuestros datos como un grafo, y por tanto no podemos aplicar esta técnica.\nIronicamente el análisis de redes sociales no se puede aplicar a nuestro dataset de Instagram."
  },
  {
    "objectID": "other_techniques.html#análisis-de-componentes-principales",
    "href": "other_techniques.html#análisis-de-componentes-principales",
    "title": "8  Otras técnicas",
    "section": "8.2 Análisis de componentes principales",
    "text": "8.2 Análisis de componentes principales\nEl análisis de componentes principales es una técnica de reducción de dimensionalidad que se utiliza para transformar un conjunto de variables posiblemente correlacionadas en un conjunto más pequeño de variables no correlacionadas llamadas componentes principales. Estos componentes capturan la mayor parte de la variabilidad presente en los datos originales, permitiendo simplificar la estructura del dataset mientras se conserva la información esencial.\nEn nuestro caso, con nuestro dataset de cuentas de Instagram, podríamos considerar aplicar PCA para intentar reducir las 12 variables disponibles a un número menor de componentes que retengan la mayor parte de la información. El problema es que estas 12 variables representan aspectos distintos y son, en general, independientes entre sí. Esto significa que no hay correlación significativa entre todas las variables (aunque si algunas como ya hemos visto), y cada una aporta información única.\nDebido a esta independencia, aplicar PCA no resultaría demasiado beneficioso. No lograríamos una reducción sustancial de la dimensionalidad sin perder información importante. Además, la interpretación de los componentes principales sería compleja y poco intuitiva, ya que no habría una estructura subyacente clara que agrupe la varianza en unos pocos componentes. Por tanto, aunque el PCA es una herramienta poderosa en muchos contextos, en este caso específico con solo 12 variables independientes, su aplicación no proporcionaría ventajas significativas en términos de simplificación o comprensión de los datos."
  },
  {
    "objectID": "predictor.html",
    "href": "predictor.html",
    "title": "9  Predictor interactivo",
    "section": "",
    "text": "Con la regresión, obtuvimos un buen modelo capaz de predecir si una cuenta de Instagram es falsa o no. Nuestro modelo5 daba muy buenos resultados.\nDado que es un modelo de regresión, lo que estamos haciendo es aplicar una fórmula matemática a nuestros datos, que nos da un resultado númerico. Este luego lo estamos binarizando y en función de si es 0 o 1 sabemos si la cuenta es real o falsa.\nPodemos implementar fácilmente dicho modelo usando JavaScript, lo que nos permite incrustar en este apartado de nuestro libro de Quarto un formulario interactivo que nos permita predecir si una cuenta es real o falsa.\n\n¿Por qué hacerlo con HTML y JavaScript si tenemos R Shiny?\n\nR Shiny necesita de un servidor para poder estar ejecutando el código R. Un navegador no ejecuta código R. Como no podemos ejecutar código R, podemos construir una página e implementar la formula de nuestro modelo. Eso es justamente lo que hemos hecho.\nEn un principio comenzamos a desarrollar este apartado de forma que solo introduciendo el nombre de usuario de Instagram de la persona, te realizaba la predicción, pero lamentablemente, la API para obtener datos de un perfil de usuario de Instagram es limitada actualmente.\nA continuación, puedes introducir los datos references a la cuenta de Instagram que desees, y al pulsar el botón Predecir cuenta obtendrás una predicción de si la cuenta que has introducido es real o falsa.\n\n\n\n  Introduce los datos de la cuenta:\n  \n    Nombre de usuario de la cuenta\n    \n  \n  \n    Nombre real\n    \n  \n  \n    Descripción (Copia y pega)\n    \n  \n  \n    Número de publicaciones\n    \n  \n  \n    Número de seguidores\n    \n  \n  \n    Número de seguidos\n    \n  \n  \n    ¿Foto de perfil?\n    \n  \n  \n    ¿Tiene enlace externo?\n    \n  \n  \n    ¿La cuenta es privada?\n    \n  \n  Predecir cuenta"
  },
  {
    "objectID": "summary.html#conclusión-final",
    "href": "summary.html#conclusión-final",
    "title": "10  Resumen",
    "section": "10.1 Conclusión final",
    "text": "10.1 Conclusión final\nCon este trabajo, hemos visto como es realmente aplicable esa teoría y práctica que vemos en la asignatura, que es más que simplemente matemáticas que damos por que tenemos que darlo, si no que tienen un uso real. El tema en cuestión de este año ha sido bastante interesante y lograr ver un uso directo y práctico de lo aprendido me parece increíble.\nPersonalmente, este año he aprendido muchas cosas en la carrera que antes de comenzar el año, si me preguntaban, diría que es imposible que yo hiciese eso, y esta es una de ellas.\nSi me llegan a decir en enero, ¿serías capaz si te doy unos datos de cuentas de Instagram y si son falsas o no, crear un código que si le metes una cuetna te diga si es falsa o no? Sinceramente diría que eso ni si quiera se ve en mi carrera, y ahora, en mayo, he conseguido hacerlo simplemente con lo aprendido en la asignatura, estoy muy orgulloso de este trabajo y me ha parecido muy interesante e ideal para esta asignatura."
  }
]